{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define our video data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ld-sgdev/shuai_li/anaconda3/envs/py37/lib/python3.7/site-packages/albumentations/imgaug/transforms.py:252: FutureWarning: IAAAdditiveGaussianNoise is deprecated. Please use GaussNoise instead\n",
      "  warnings.warn(\"IAAAdditiveGaussianNoise is deprecated. Please use GaussNoise instead\", FutureWarning)\n",
      "/home/ld-sgdev/shuai_li/anaconda3/envs/py37/lib/python3.7/site-packages/albumentations/imgaug/transforms.py:222: FutureWarning: IAASharpen is deprecated. Please use Sharpen instead\n",
      "  warnings.warn(\"IAASharpen is deprecated. Please use Sharpen instead\", FutureWarning)\n",
      "/home/ld-sgdev/shuai_li/anaconda3/envs/py37/lib/python3.7/site-packages/albumentations/imgaug/transforms.py:165: FutureWarning: This augmentation is deprecated. Please use Emboss instead\n",
      "  warnings.warn(\"This augmentation is deprecated. Please use Emboss instead\", FutureWarning)\n",
      "/home/ld-sgdev/shuai_li/anaconda3/envs/py37/lib/python3.7/site-packages/albumentations/imgaug/transforms.py:375: FutureWarning: This IAAPerspective is deprecated. Please use Perspective instead\n",
      "  warnings.warn(\"This IAAPerspective is deprecated. Please use Perspective instead\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import albumentations as A\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# data augmentation for training\n",
    "augmentation = A.Compose([\n",
    "    A.OneOf([\n",
    "        A.IAAAdditiveGaussianNoise(p=0.9),\n",
    "        A.GaussNoise(p=0.9),\n",
    "    ], p=0.9),\n",
    "    A.OneOf([\n",
    "        A.MotionBlur(p=0.9),\n",
    "        A.MedianBlur(blur_limit=3, p=0.9),\n",
    "        A.Blur(blur_limit=4, p=0.9),\n",
    "    ], p=0.9),\n",
    "    A.OneOf([\n",
    "        A.CLAHE(clip_limit=2, p=0.9),\n",
    "        A.IAASharpen(p=0.9),\n",
    "        A.IAAEmboss(p=0.9),\n",
    "        A.RandomBrightnessContrast(p=0.95),\n",
    "    ], p=0.9),\n",
    "    A.OneOf(\n",
    "        [\n",
    "            A.HueSaturationValue(p=0.9),\n",
    "            A.RandomGamma(p=0.9),\n",
    "            A.IAAPerspective(p=0.05),\n",
    "        ], p=0.9,\n",
    "    )\n",
    "])\n",
    "\n",
    "\n",
    "def build_transform(shape):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((shape[0], shape[1])),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "    return transform\n",
    "\n",
    "\n",
    "class VideoDataset(Dataset):\n",
    "    def __init__(self, folder_list, char_dict,\n",
    "                 fixed_frame_num=200, fixed_max_len=6,\n",
    "                 image_shape=(100, 100),\n",
    "                 aug=augmentation):\n",
    "        \"\"\"\n",
    "        \n",
    "        :param folder_list: video image folders for training or validation\n",
    "        :param char_dict: \n",
    "        :param fixed_frame_num: \n",
    "        :param fixed_max_len: \n",
    "        :param image_shape: \n",
    "        :param aug: whether to use data augmentation or not, None or augmentation object\n",
    "        \"\"\"\n",
    "        self.folders = folder_list\n",
    "        np.random.shuffle(self.folders)\n",
    "        self.fixed_frame_num = fixed_frame_num\n",
    "        self.char_dict = char_dict\n",
    "        self.fixed_max_len = fixed_max_len\n",
    "        self.augmentation = aug\n",
    "        self.image_shape = image_shape\n",
    "        self.transform = build_transform(shape=self.image_shape)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.folders)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_folder = self.folders[index]\n",
    "        label = image_folder.split(\"/\")[-1].split(\"_\")[-1].strip(\" \")\n",
    "        # encode the char text to class index for training\n",
    "        label_digit = [self.char_dict[i] for i in label]\n",
    "        assert len(label_digit) < self.fixed_max_len\n",
    "        label_digit.append(self.char_dict[\"<eos>\"])\n",
    "        rest = self.fixed_max_len - len(label_digit)\n",
    "        if rest:\n",
    "            label_digit += [self.char_dict[\"<blank>\"]] * rest\n",
    "\n",
    "        image_list = [os.path.join(image_folder, i) for i in os.listdir(image_folder) if i.endswith(\".jpg\")]\n",
    "        image_list = sorted(image_list)\n",
    "        images = []\n",
    "    \n",
    "        if len(image_list) >= self.fixed_frame_num:\n",
    "            # due to GPU limitation, we can not generate too huge videos,\n",
    "            # so we have to set a fixed max frame number\n",
    "            image_list = image_list[:self.fixed_frame_num]\n",
    "        else:\n",
    "            # if the image number is lower than fixed frame number, we pad it with default RGB images\n",
    "            image_list += [\"pad\"] * (self.fixed_frame_num - len(image_list))\n",
    "\n",
    "        for i in image_list:\n",
    "            if i != \"pad\":\n",
    "                img = Image.open(i).convert(\"RGB\")\n",
    "                if self.augmentation is not None:\n",
    "                    img = self.augmentation(image=np.array(img, dtype=np.uint8))[\"image\"]\n",
    "                    img = Image.fromarray(img)\n",
    "            else:\n",
    "                img = Image.new(\"RGB\", (self.image_shape[1], self.image_shape[0]))\n",
    "\n",
    "            img = self.transform(img)\n",
    "            images.append(img)\n",
    "        x = torch.stack(images)\n",
    "        y = torch.tensor(label_digit, dtype=torch.long)\n",
    "        return x, y\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build 3DCNN + RNN lipsreading  model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class BidirectionalLSTM(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, nIn, nHidden, nOut):\n",
    "        super(BidirectionalLSTM, self).__init__()\n",
    "\n",
    "        self.rnn = torch.nn.LSTM(nIn, nHidden, bidirectional=True, batch_first=True)\n",
    "        self.embedding = torch.nn.Linear(nHidden * 2, nOut)\n",
    "        # self.embedding_1 = torch.nn.Linear(nHidden * 2, nHidden)\n",
    "        # self.embedding_2 = torch.nn.Linear(nHidden, nHidden//2)\n",
    "        # self.embedding_3 = torch.nn.Linear(nHidden//2, nOut)\n",
    "        # self.dropout_1 = torch.nn.Dropout(p=0.1)\n",
    "        # self.dropout_2 = torch.nn.Dropout(p=0.25)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        recurrent, _ = self.rnn(inputs)\n",
    "        T, b, h = recurrent.size()\n",
    "        t_rec = recurrent.reshape(T * b, h)\n",
    "\n",
    "        # output = self.embedding_1(t_rec)  # [T * b, nOut]\n",
    "        # output = self.dropout_1(output)\n",
    "        # output = F.relu(output)\n",
    "        #\n",
    "        # output = self.embedding_2(output)\n",
    "        # # output = self.dropout_2(output)\n",
    "        # output = F.relu(output)\n",
    "        #\n",
    "        # output = self.embedding_3(output)\n",
    "\n",
    "        output = self.embedding(t_rec)\n",
    "\n",
    "        output = output.reshape(T, b, -1)\n",
    "        # output = F.softmax(output, dim=-1)\n",
    "        return output\n",
    "\n",
    "\n",
    "class VideoModel(torch.nn.Module):\n",
    "    def __init__(self, number_classes=28, max_len=6, image_shape=(100, 100)):\n",
    "        \"\"\"\n",
    "\n",
    "        :param number_classes:\n",
    "        our char dictionary is:\n",
    "        0: <blank>\n",
    "        1: a\n",
    "        2: b\n",
    "        3: c\n",
    "        ...\n",
    "        26: z\n",
    "        27: <eos>\n",
    "        :param max_len: max_len = 6,\n",
    "        Suppose we said abcde,\n",
    "        the the label should be abcde<eos>\n",
    "        abc -> abc<eos><blank><blank>\n",
    "        number_classes = 28, 26 characters + <eos> + <blank>\n",
    "        \"\"\"\n",
    "        super(VideoModel, self).__init__()\n",
    "        self.number_classes = number_classes\n",
    "        self.max_len = max_len\n",
    "        self.conv_block_1 = self._conv_block(3, 32)\n",
    "        self.conv_block_2 = self._conv_block(32, 64)\n",
    "        self.conv_block_3 = self._conv_block(64, 128)\n",
    "        self.conv_block_4 = self._conv_block(128, 256)\n",
    "        assert image_shape[0] in [100, 60]\n",
    "        nIn = 21504 if image_shape[0] == 100 else 5376\n",
    "        self.lstm_decoder = BidirectionalLSTM(nIn=nIn,\n",
    "                                              nHidden=256,\n",
    "                                              nOut=number_classes)\n",
    "\n",
    "    def _conv_block(self, input_c, output_c):\n",
    "        conv_block = torch.nn.Sequential(\n",
    "            torch.nn.Conv3d(input_c, output_c, kernel_size=(3, 3, 2), padding=1),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            # torch.nn.BatchNorm3d(output_c),\n",
    "            torch.nn.Conv3d(output_c, output_c, kernel_size=(3, 3, 2), padding=1),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            # torch.nn.BatchNorm3d(output_c),\n",
    "            torch.nn.MaxPool3d((2, 2, 2))\n",
    "        )\n",
    "        return conv_block\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.permute(dims=(0, 2, 3, 4, 1))\n",
    "        x = self.conv_block_1(x)\n",
    "        x = self.conv_block_2(x)\n",
    "        x = self.conv_block_3(x)\n",
    "        x = self.conv_block_4(x)\n",
    "        shape = x.size()\n",
    "        # bs, 256, 3, 3, 14\n",
    "        x = x.view(shape[0], self.max_len, -1)  # bs, max_len, rest\n",
    "        x = self.lstm_decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define the dataloader in this task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "{'<blank>': 0, 'a': 1, 'b': 2, 'c': 3, 'd': 4, 'e': 5, 'f': 6, 'g': 7, 'h': 8, 'i': 9, 'j': 10, 'k': 11, 'l': 12, 'm': 13, 'n': 14, 'o': 15, 'p': 16, 'q': 17, 'r': 18, 's': 19, 't': 20, 'u': 21, 'v': 22, 'w': 23, 'x': 24, 'y': 25, 'z': 26, '<eos>': 27}\n",
      "train videos:171\n",
      "test videos:20\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import string\n",
    "import time\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "\n",
    "def make_char_dict():\n",
    "    chars = string.ascii_lowercase\n",
    "    char_dict = {\"<blank>\": 0}\n",
    "    for idx, c in enumerate(chars):\n",
    "        char_dict[c] = idx + 1\n",
    "    current_len = len(list(char_dict.keys()))\n",
    "    char_dict[\"<eos>\"] = current_len\n",
    "    print(char_dict)\n",
    "    return char_dict\n",
    "\n",
    "\n",
    "def get_train_test_folders():\n",
    "    test = open(\"data/eval_lst.txt\", \"r\", encoding=\"utf-8\").readlines()\n",
    "    train = open(\"data/train_lst.txt\", \"r\", encoding=\"utf-8\").readlines()\n",
    "    train_folders = [os.path.join(\"data\", \"data_aligned\", i.strip(\"\\n\")) for i in train]\n",
    "    test_folders = [os.path.join(\"data\", \"data_aligned\", i.strip(\"\\n\")) for i in test]\n",
    "    print(\"train videos:{}\".format(len(train_folders)))\n",
    "    print(\"test videos:{}\".format(len(test_folders)))\n",
    "    return train_folders, test_folders\n",
    "\n",
    "\n",
    "image_shape = (60, 60)\n",
    "\n",
    "char_dict = make_char_dict()\n",
    "train_folders, test_folders = get_train_test_folders()\n",
    "train_dataset = VideoDataset(\n",
    "    folder_list=train_folders,\n",
    "    char_dict=char_dict,\n",
    "    fixed_frame_num=200,\n",
    "    fixed_max_len=6,\n",
    "    image_shape=image_shape,\n",
    ")\n",
    "batch_size = 10\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset, batch_size=batch_size, shuffle=True\n",
    ")\n",
    "test_dataset = VideoDataset(\n",
    "    folder_list=test_folders,\n",
    "    char_dict=char_dict,\n",
    "    fixed_frame_num=200,\n",
    "    fixed_max_len=6,\n",
    "    aug=None,  # No need to do data augmentation in testing dataset\n",
    "    image_shape=image_shape,\n",
    ")\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset, batch_size=batch_size, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## init our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VideoModel(\n",
      "  (conv_block_1): Sequential(\n",
      "    (0): Conv3d(3, 32, kernel_size=(3, 3, 2), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "    (1): LeakyReLU(negative_slope=0.01)\n",
      "    (2): Conv3d(32, 32, kernel_size=(3, 3, 2), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "    (3): LeakyReLU(negative_slope=0.01)\n",
      "    (4): MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv_block_2): Sequential(\n",
      "    (0): Conv3d(32, 64, kernel_size=(3, 3, 2), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "    (1): LeakyReLU(negative_slope=0.01)\n",
      "    (2): Conv3d(64, 64, kernel_size=(3, 3, 2), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "    (3): LeakyReLU(negative_slope=0.01)\n",
      "    (4): MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv_block_3): Sequential(\n",
      "    (0): Conv3d(64, 128, kernel_size=(3, 3, 2), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "    (1): LeakyReLU(negative_slope=0.01)\n",
      "    (2): Conv3d(128, 128, kernel_size=(3, 3, 2), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "    (3): LeakyReLU(negative_slope=0.01)\n",
      "    (4): MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv_block_4): Sequential(\n",
      "    (0): Conv3d(128, 256, kernel_size=(3, 3, 2), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "    (1): LeakyReLU(negative_slope=0.01)\n",
      "    (2): Conv3d(256, 256, kernel_size=(3, 3, 2), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "    (3): LeakyReLU(negative_slope=0.01)\n",
      "    (4): MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (lstm_decoder): BidirectionalLSTM(\n",
      "    (rnn): LSTM(5376, 256, batch_first=True, bidirectional=True)\n",
      "    (embedding): Linear(in_features=512, out_features=28, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = VideoModel(number_classes=len(list(char_dict.keys())),\n",
    "                   max_len=6,\n",
    "                   image_shape=image_shape)\n",
    "model = model.to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## setup the loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## setup the training epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in real traning process, we set 300 epochs with early stopping,\n",
    "# here we just use 10 epochs to show the entire pipeline for your reference\n",
    "epochs = 10  # for easy running"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## setup learning rate scheduler for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,\n",
    "                                                       mode='min',\n",
    "                                                       verbose=True,\n",
    "                                                       factor=0.1,\n",
    "                                                       patience=5,\n",
    "                                                       threshold=0.00001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define the acc metric function of our task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_val_acc(scores, y):\n",
    "    num = scores.size(0)\n",
    "    prediction = scores.argmax(dim=1)\n",
    "    indicator = (prediction == y)\n",
    "    num_matches = indicator.sum()\n",
    "    return num_matches.float() / num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## summarize the training process as a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_process():\n",
    "    running_loss = 0\n",
    "    num_batches = 0\n",
    "\n",
    "    model.train()\n",
    "    for idx, data in enumerate(train_dataloader):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        x, y = data\n",
    "        size = y.size()\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        x.requires_grad_()\n",
    "\n",
    "        scores = model(x)\n",
    "\n",
    "        scores = scores.view(size[0] * size[1], -1)\n",
    "        y = y.view(size[0] * size[1])\n",
    "        loss = criterion(scores, y)\n",
    "\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 5)\n",
    "        optimizer.step()\n",
    "        running_loss += loss.detach().item()\n",
    "        num_batches += 1\n",
    "        print(\"time:{}, epoch: {} step: {}, avg running loss is {}\".format(\n",
    "            time.ctime(), epoch + 1, idx + 1, running_loss / num_batches\n",
    "        ))\n",
    "    return running_loss, num_batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## summarize the validation process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing_process():\n",
    "    running_loss = 0\n",
    "    num_batches = 0\n",
    "    running_acc = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for idx, data in enumerate(test_dataloader):\n",
    "            x, y = data\n",
    "            size = y.size()\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            scores = model(x)\n",
    "\n",
    "            scores = scores.view(size[0] * size[1], -1)\n",
    "            y = y.view(size[0] * size[1])\n",
    "            loss = criterion(scores, y)\n",
    "            running_loss += loss.item()\n",
    "            num_batches += 1\n",
    "            running_acc += compute_val_acc(scores, y)\n",
    "    return running_loss, num_batches, running_acc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training and evaluate models for each epoch  \n",
    "#### plus: using learning rate scheduler to improve the performance\n",
    "#### plus: using early stopping for real training task to avoid over-fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time:Wed Nov 17 21:45:39 2021, epoch: 1 step: 1, avg running loss is 3.3444902896881104\n",
      "time:Wed Nov 17 21:45:46 2021, epoch: 1 step: 2, avg running loss is 3.3380552530288696\n",
      "time:Wed Nov 17 21:45:53 2021, epoch: 1 step: 3, avg running loss is 3.330162763595581\n",
      "time:Wed Nov 17 21:46:01 2021, epoch: 1 step: 4, avg running loss is 3.311287820339203\n",
      "time:Wed Nov 17 21:46:08 2021, epoch: 1 step: 5, avg running loss is 3.292432117462158\n",
      "time:Wed Nov 17 21:46:16 2021, epoch: 1 step: 6, avg running loss is 3.271060347557068\n",
      "time:Wed Nov 17 21:46:24 2021, epoch: 1 step: 7, avg running loss is 3.2505810260772705\n",
      "time:Wed Nov 17 21:46:31 2021, epoch: 1 step: 8, avg running loss is 3.2124876379966736\n",
      "time:Wed Nov 17 21:46:38 2021, epoch: 1 step: 9, avg running loss is 3.1843248473273382\n",
      "time:Wed Nov 17 21:46:46 2021, epoch: 1 step: 10, avg running loss is 3.140131688117981\n",
      "time:Wed Nov 17 21:46:51 2021, epoch: 1 step: 11, avg running loss is 3.075522921302102\n",
      "time:Wed Nov 17 21:46:57 2021, epoch: 1 step: 12, avg running loss is 3.0183775424957275\n",
      "time:Wed Nov 17 21:47:04 2021, epoch: 1 step: 13, avg running loss is 2.9832723507514367\n",
      "time:Wed Nov 17 21:47:11 2021, epoch: 1 step: 14, avg running loss is 2.932998674256461\n",
      "time:Wed Nov 17 21:47:18 2021, epoch: 1 step: 15, avg running loss is 2.9281253019968667\n",
      "time:Wed Nov 17 21:47:27 2021, epoch: 1 step: 16, avg running loss is 2.9082871228456497\n",
      "time:Wed Nov 17 21:47:35 2021, epoch: 1 step: 17, avg running loss is 2.8833148619707893\n",
      "time:Wed Nov 17 21:47:35 2021, epoch: 1 step: 18, avg running loss is 2.8536153634389243\n",
      "****************************************************************************************************\n",
      "epoch: 1, avg training loss:2.8536153634389243, avg validation loss:2.533716559410095, validation acc: 0.28333336114883423\n",
      "****************************************************************************************************\n",
      "save best model in best_3D_model.pt\n",
      "time:Wed Nov 17 21:47:46 2021, epoch: 2 step: 1, avg running loss is 2.566753625869751\n",
      "time:Wed Nov 17 21:47:54 2021, epoch: 2 step: 2, avg running loss is 2.512570023536682\n",
      "time:Wed Nov 17 21:48:02 2021, epoch: 2 step: 3, avg running loss is 2.4481611251831055\n",
      "time:Wed Nov 17 21:48:09 2021, epoch: 2 step: 4, avg running loss is 2.4078494906425476\n",
      "time:Wed Nov 17 21:48:16 2021, epoch: 2 step: 5, avg running loss is 2.3614172458648683\n",
      "time:Wed Nov 17 21:48:24 2021, epoch: 2 step: 6, avg running loss is 2.3380180994669595\n",
      "time:Wed Nov 17 21:48:32 2021, epoch: 2 step: 7, avg running loss is 2.359581368310111\n",
      "time:Wed Nov 17 21:48:39 2021, epoch: 2 step: 8, avg running loss is 2.3428986370563507\n",
      "time:Wed Nov 17 21:48:46 2021, epoch: 2 step: 9, avg running loss is 2.317562209235297\n",
      "time:Wed Nov 17 21:48:52 2021, epoch: 2 step: 10, avg running loss is 2.315132999420166\n",
      "time:Wed Nov 17 21:48:59 2021, epoch: 2 step: 11, avg running loss is 2.3098850033499976\n",
      "time:Wed Nov 17 21:49:06 2021, epoch: 2 step: 12, avg running loss is 2.3069037397702536\n",
      "time:Wed Nov 17 21:49:12 2021, epoch: 2 step: 13, avg running loss is 2.284306342785175\n",
      "time:Wed Nov 17 21:49:19 2021, epoch: 2 step: 14, avg running loss is 2.2798604794910977\n",
      "time:Wed Nov 17 21:49:26 2021, epoch: 2 step: 15, avg running loss is 2.285309060414632\n",
      "time:Wed Nov 17 21:49:35 2021, epoch: 2 step: 16, avg running loss is 2.305889144539833\n",
      "time:Wed Nov 17 21:49:41 2021, epoch: 2 step: 17, avg running loss is 2.295691265779383\n",
      "time:Wed Nov 17 21:49:42 2021, epoch: 2 step: 18, avg running loss is 2.327150172657437\n",
      "****************************************************************************************************\n",
      "epoch: 2, avg training loss:2.327150172657437, avg validation loss:2.468370795249939, validation acc: 0.2916666865348816\n",
      "****************************************************************************************************\n",
      "save best model in best_3D_model.pt\n",
      "time:Wed Nov 17 21:49:53 2021, epoch: 3 step: 1, avg running loss is 2.1434998512268066\n",
      "time:Wed Nov 17 21:49:58 2021, epoch: 3 step: 2, avg running loss is 1.9983040690422058\n",
      "time:Wed Nov 17 21:50:06 2021, epoch: 3 step: 3, avg running loss is 2.1343264977137246\n",
      "time:Wed Nov 17 21:50:13 2021, epoch: 3 step: 4, avg running loss is 2.1093473732471466\n",
      "time:Wed Nov 17 21:50:20 2021, epoch: 3 step: 5, avg running loss is 2.165204119682312\n",
      "time:Wed Nov 17 21:50:29 2021, epoch: 3 step: 6, avg running loss is 2.236606458822886\n",
      "time:Wed Nov 17 21:50:38 2021, epoch: 3 step: 7, avg running loss is 2.2399782964161465\n",
      "time:Wed Nov 17 21:50:45 2021, epoch: 3 step: 8, avg running loss is 2.2325600534677505\n",
      "time:Wed Nov 17 21:50:52 2021, epoch: 3 step: 9, avg running loss is 2.260895848274231\n",
      "time:Wed Nov 17 21:50:59 2021, epoch: 3 step: 10, avg running loss is 2.2606243968009947\n",
      "time:Wed Nov 17 21:51:06 2021, epoch: 3 step: 11, avg running loss is 2.2378390810706397\n",
      "time:Wed Nov 17 21:51:13 2021, epoch: 3 step: 12, avg running loss is 2.2176710069179535\n",
      "time:Wed Nov 17 21:51:19 2021, epoch: 3 step: 13, avg running loss is 2.1938408521505504\n",
      "time:Wed Nov 17 21:51:27 2021, epoch: 3 step: 14, avg running loss is 2.196901559829712\n",
      "time:Wed Nov 17 21:51:35 2021, epoch: 3 step: 15, avg running loss is 2.2124992688496907\n",
      "time:Wed Nov 17 21:51:42 2021, epoch: 3 step: 16, avg running loss is 2.229250803589821\n",
      "time:Wed Nov 17 21:51:52 2021, epoch: 3 step: 17, avg running loss is 2.254757656770594\n",
      "time:Wed Nov 17 21:51:52 2021, epoch: 3 step: 18, avg running loss is 2.283717407120599\n",
      "****************************************************************************************************\n",
      "epoch: 3, avg training loss:2.283717407120599, avg validation loss:2.4583094120025635, validation acc: 0.30000001192092896\n",
      "****************************************************************************************************\n",
      "save best model in best_3D_model.pt\n",
      "time:Wed Nov 17 21:52:03 2021, epoch: 4 step: 1, avg running loss is 2.2526440620422363\n",
      "time:Wed Nov 17 21:52:10 2021, epoch: 4 step: 2, avg running loss is 2.129051923751831\n",
      "time:Wed Nov 17 21:52:18 2021, epoch: 4 step: 3, avg running loss is 2.266093889872233\n",
      "time:Wed Nov 17 21:52:24 2021, epoch: 4 step: 4, avg running loss is 2.2511497735977173\n",
      "time:Wed Nov 17 21:52:31 2021, epoch: 4 step: 5, avg running loss is 2.26234393119812\n",
      "time:Wed Nov 17 21:52:39 2021, epoch: 4 step: 6, avg running loss is 2.296279191970825\n",
      "time:Wed Nov 17 21:52:46 2021, epoch: 4 step: 7, avg running loss is 2.266768898282732\n",
      "time:Wed Nov 17 21:52:54 2021, epoch: 4 step: 8, avg running loss is 2.285332977771759\n",
      "time:Wed Nov 17 21:52:59 2021, epoch: 4 step: 9, avg running loss is 2.2546973493364124\n",
      "time:Wed Nov 17 21:53:05 2021, epoch: 4 step: 10, avg running loss is 2.2372704267501833\n",
      "time:Wed Nov 17 21:53:10 2021, epoch: 4 step: 11, avg running loss is 2.2362965020266445\n",
      "time:Wed Nov 17 21:53:17 2021, epoch: 4 step: 12, avg running loss is 2.238929589589437\n",
      "time:Wed Nov 17 21:53:27 2021, epoch: 4 step: 13, avg running loss is 2.3184174390939565\n",
      "time:Wed Nov 17 21:53:35 2021, epoch: 4 step: 14, avg running loss is 2.3362912109919955\n",
      "time:Wed Nov 17 21:53:41 2021, epoch: 4 step: 15, avg running loss is 2.312292798360189\n",
      "time:Wed Nov 17 21:53:48 2021, epoch: 4 step: 16, avg running loss is 2.3058861196041107\n",
      "time:Wed Nov 17 21:53:54 2021, epoch: 4 step: 17, avg running loss is 2.2956533011268165\n",
      "time:Wed Nov 17 21:53:54 2021, epoch: 4 step: 18, avg running loss is 2.2524285912513733\n",
      "****************************************************************************************************\n",
      "epoch: 4, avg training loss:2.2524285912513733, avg validation loss:2.4430291652679443, validation acc: 0.3083333373069763\n",
      "****************************************************************************************************\n",
      "save best model in best_3D_model.pt\n",
      "time:Wed Nov 17 21:54:05 2021, epoch: 5 step: 1, avg running loss is 2.283545732498169\n",
      "time:Wed Nov 17 21:54:12 2021, epoch: 5 step: 2, avg running loss is 2.257429599761963\n",
      "time:Wed Nov 17 21:54:19 2021, epoch: 5 step: 3, avg running loss is 2.2347724437713623\n",
      "time:Wed Nov 17 21:54:26 2021, epoch: 5 step: 4, avg running loss is 2.2593671679496765\n",
      "time:Wed Nov 17 21:54:34 2021, epoch: 5 step: 5, avg running loss is 2.281436634063721\n",
      "time:Wed Nov 17 21:54:41 2021, epoch: 5 step: 6, avg running loss is 2.3151149352391562\n",
      "time:Wed Nov 17 21:54:48 2021, epoch: 5 step: 7, avg running loss is 2.362770148686\n",
      "time:Wed Nov 17 21:54:55 2021, epoch: 5 step: 8, avg running loss is 2.3257358074188232\n",
      "time:Wed Nov 17 21:55:02 2021, epoch: 5 step: 9, avg running loss is 2.313155253728231\n",
      "time:Wed Nov 17 21:55:10 2021, epoch: 5 step: 10, avg running loss is 2.3076101303100587\n",
      "time:Wed Nov 17 21:55:17 2021, epoch: 5 step: 11, avg running loss is 2.300163073973222\n",
      "time:Wed Nov 17 21:55:24 2021, epoch: 5 step: 12, avg running loss is 2.287144680817922\n",
      "time:Wed Nov 17 21:55:29 2021, epoch: 5 step: 13, avg running loss is 2.251230790064885\n",
      "time:Wed Nov 17 21:55:37 2021, epoch: 5 step: 14, avg running loss is 2.2411017417907715\n",
      "time:Wed Nov 17 21:55:44 2021, epoch: 5 step: 15, avg running loss is 2.2284300645192463\n",
      "time:Wed Nov 17 21:55:50 2021, epoch: 5 step: 16, avg running loss is 2.2289822101593018\n",
      "time:Wed Nov 17 21:55:59 2021, epoch: 5 step: 17, avg running loss is 2.238211182986989\n",
      "time:Wed Nov 17 21:55:59 2021, epoch: 5 step: 18, avg running loss is 2.199429670969645\n",
      "****************************************************************************************************\n",
      "epoch: 5, avg training loss:2.199429670969645, avg validation loss:2.5414652824401855, validation acc: 0.3083333373069763\n",
      "****************************************************************************************************\n",
      "time:Wed Nov 17 21:56:10 2021, epoch: 6 step: 1, avg running loss is 2.2865092754364014\n",
      "time:Wed Nov 17 21:56:17 2021, epoch: 6 step: 2, avg running loss is 2.2197874784469604\n",
      "time:Wed Nov 17 21:56:24 2021, epoch: 6 step: 3, avg running loss is 2.3386106491088867\n",
      "time:Wed Nov 17 21:56:30 2021, epoch: 6 step: 4, avg running loss is 2.2805612683296204\n",
      "time:Wed Nov 17 21:56:37 2021, epoch: 6 step: 5, avg running loss is 2.290626811981201\n",
      "time:Wed Nov 17 21:56:43 2021, epoch: 6 step: 6, avg running loss is 2.2283880909283957\n",
      "time:Wed Nov 17 21:56:50 2021, epoch: 6 step: 7, avg running loss is 2.2064542940684726\n",
      "time:Wed Nov 17 21:56:59 2021, epoch: 6 step: 8, avg running loss is 2.242372825741768\n",
      "time:Wed Nov 17 21:57:05 2021, epoch: 6 step: 9, avg running loss is 2.219848142729865\n",
      "time:Wed Nov 17 21:57:12 2021, epoch: 6 step: 10, avg running loss is 2.198712980747223\n",
      "time:Wed Nov 17 21:57:20 2021, epoch: 6 step: 11, avg running loss is 2.216645359992981\n",
      "time:Wed Nov 17 21:57:27 2021, epoch: 6 step: 12, avg running loss is 2.212420513232549\n",
      "time:Wed Nov 17 21:57:33 2021, epoch: 6 step: 13, avg running loss is 2.2127191378520084\n",
      "time:Wed Nov 17 21:57:40 2021, epoch: 6 step: 14, avg running loss is 2.21045629467283\n",
      "time:Wed Nov 17 21:57:45 2021, epoch: 6 step: 15, avg running loss is 2.2035165707270306\n",
      "time:Wed Nov 17 21:57:53 2021, epoch: 6 step: 16, avg running loss is 2.2323058918118477\n",
      "time:Wed Nov 17 21:57:59 2021, epoch: 6 step: 17, avg running loss is 2.234495857182671\n",
      "time:Wed Nov 17 21:57:59 2021, epoch: 6 step: 18, avg running loss is 2.201601439052158\n",
      "****************************************************************************************************\n",
      "epoch: 6, avg training loss:2.201601439052158, avg validation loss:2.4511650800704956, validation acc: 0.2916666865348816\n",
      "****************************************************************************************************\n",
      "time:Wed Nov 17 21:58:07 2021, epoch: 7 step: 1, avg running loss is 2.036935567855835\n",
      "time:Wed Nov 17 21:58:14 2021, epoch: 7 step: 2, avg running loss is 2.0424656867980957\n",
      "time:Wed Nov 17 21:58:20 2021, epoch: 7 step: 3, avg running loss is 2.0667383670806885\n",
      "time:Wed Nov 17 21:58:27 2021, epoch: 7 step: 4, avg running loss is 2.162369728088379\n",
      "time:Wed Nov 17 21:58:34 2021, epoch: 7 step: 5, avg running loss is 2.1499329090118406\n",
      "time:Wed Nov 17 21:58:39 2021, epoch: 7 step: 6, avg running loss is 2.078733523686727\n",
      "time:Wed Nov 17 21:58:46 2021, epoch: 7 step: 7, avg running loss is 2.135594572339739\n",
      "time:Wed Nov 17 21:58:52 2021, epoch: 7 step: 8, avg running loss is 2.111862063407898\n",
      "time:Wed Nov 17 21:58:58 2021, epoch: 7 step: 9, avg running loss is 2.131042957305908\n",
      "time:Wed Nov 17 21:59:04 2021, epoch: 7 step: 10, avg running loss is 2.109842872619629\n",
      "time:Wed Nov 17 21:59:11 2021, epoch: 7 step: 11, avg running loss is 2.1407413482666016\n",
      "time:Wed Nov 17 21:59:17 2021, epoch: 7 step: 12, avg running loss is 2.1408999959627786\n",
      "time:Wed Nov 17 21:59:24 2021, epoch: 7 step: 13, avg running loss is 2.161463058911837\n",
      "time:Wed Nov 17 21:59:30 2021, epoch: 7 step: 14, avg running loss is 2.178766591208322\n",
      "time:Wed Nov 17 21:59:37 2021, epoch: 7 step: 15, avg running loss is 2.187538576126099\n",
      "time:Wed Nov 17 21:59:44 2021, epoch: 7 step: 16, avg running loss is 2.1953014731407166\n",
      "time:Wed Nov 17 21:59:51 2021, epoch: 7 step: 17, avg running loss is 2.2160195462843952\n",
      "time:Wed Nov 17 21:59:51 2021, epoch: 7 step: 18, avg running loss is 2.192331612110138\n",
      "****************************************************************************************************\n",
      "epoch: 7, avg training loss:2.192331612110138, avg validation loss:2.438558578491211, validation acc: 0.2666666805744171\n",
      "****************************************************************************************************\n",
      "save best model in best_3D_model.pt\n",
      "time:Wed Nov 17 22:00:00 2021, epoch: 8 step: 1, avg running loss is 2.2062323093414307\n",
      "time:Wed Nov 17 22:00:06 2021, epoch: 8 step: 2, avg running loss is 2.1536022424697876\n",
      "time:Wed Nov 17 22:00:13 2021, epoch: 8 step: 3, avg running loss is 2.1829745769500732\n",
      "time:Wed Nov 17 22:00:20 2021, epoch: 8 step: 4, avg running loss is 2.189606785774231\n",
      "time:Wed Nov 17 22:00:27 2021, epoch: 8 step: 5, avg running loss is 2.277943563461304\n",
      "time:Wed Nov 17 22:00:34 2021, epoch: 8 step: 6, avg running loss is 2.2466506163279214\n",
      "time:Wed Nov 17 22:00:40 2021, epoch: 8 step: 7, avg running loss is 2.225823777062552\n",
      "time:Wed Nov 17 22:00:46 2021, epoch: 8 step: 8, avg running loss is 2.219925582408905\n",
      "time:Wed Nov 17 22:00:51 2021, epoch: 8 step: 9, avg running loss is 2.2057215107811823\n",
      "time:Wed Nov 17 22:00:57 2021, epoch: 8 step: 10, avg running loss is 2.1805464744567873\n",
      "time:Wed Nov 17 22:01:03 2021, epoch: 8 step: 11, avg running loss is 2.1785470138896597\n",
      "time:Wed Nov 17 22:01:09 2021, epoch: 8 step: 12, avg running loss is 2.162599116563797\n",
      "time:Wed Nov 17 22:01:15 2021, epoch: 8 step: 13, avg running loss is 2.174333068040701\n",
      "time:Wed Nov 17 22:01:20 2021, epoch: 8 step: 14, avg running loss is 2.160858835492815\n",
      "time:Wed Nov 17 22:01:28 2021, epoch: 8 step: 15, avg running loss is 2.189571412404378\n",
      "time:Wed Nov 17 22:01:34 2021, epoch: 8 step: 16, avg running loss is 2.189532443881035\n",
      "time:Wed Nov 17 22:01:40 2021, epoch: 8 step: 17, avg running loss is 2.2183978838079117\n",
      "time:Wed Nov 17 22:01:41 2021, epoch: 8 step: 18, avg running loss is 2.172337916162279\n",
      "****************************************************************************************************\n",
      "epoch: 8, avg training loss:2.172337916162279, avg validation loss:2.452992796897888, validation acc: 0.30000001192092896\n",
      "****************************************************************************************************\n",
      "time:Wed Nov 17 22:01:50 2021, epoch: 9 step: 1, avg running loss is 2.3872456550598145\n",
      "time:Wed Nov 17 22:01:56 2021, epoch: 9 step: 2, avg running loss is 2.246156692504883\n",
      "time:Wed Nov 17 22:02:01 2021, epoch: 9 step: 3, avg running loss is 2.149682402610779\n",
      "time:Wed Nov 17 22:02:07 2021, epoch: 9 step: 4, avg running loss is 2.158593326807022\n",
      "time:Wed Nov 17 22:02:13 2021, epoch: 9 step: 5, avg running loss is 2.1643903493881225\n",
      "time:Wed Nov 17 22:02:21 2021, epoch: 9 step: 6, avg running loss is 2.1837033232053122\n",
      "time:Wed Nov 17 22:02:27 2021, epoch: 9 step: 7, avg running loss is 2.1819442170006886\n",
      "time:Wed Nov 17 22:02:32 2021, epoch: 9 step: 8, avg running loss is 2.144421771168709\n",
      "time:Wed Nov 17 22:02:39 2021, epoch: 9 step: 9, avg running loss is 2.189469165272183\n",
      "time:Wed Nov 17 22:02:47 2021, epoch: 9 step: 10, avg running loss is 2.2137306809425352\n",
      "time:Wed Nov 17 22:02:54 2021, epoch: 9 step: 11, avg running loss is 2.2348215905102817\n",
      "time:Wed Nov 17 22:03:00 2021, epoch: 9 step: 12, avg running loss is 2.2381902833779654\n",
      "time:Wed Nov 17 22:03:06 2021, epoch: 9 step: 13, avg running loss is 2.2340043232991147\n",
      "time:Wed Nov 17 22:03:12 2021, epoch: 9 step: 14, avg running loss is 2.214312936578478\n",
      "time:Wed Nov 17 22:03:17 2021, epoch: 9 step: 15, avg running loss is 2.216923785209656\n",
      "time:Wed Nov 17 22:03:24 2021, epoch: 9 step: 16, avg running loss is 2.2150798812508583\n",
      "time:Wed Nov 17 22:03:31 2021, epoch: 9 step: 17, avg running loss is 2.2227048102547142\n",
      "time:Wed Nov 17 22:03:31 2021, epoch: 9 step: 18, avg running loss is 2.1924193501472473\n",
      "****************************************************************************************************\n",
      "epoch: 9, avg training loss:2.1924193501472473, avg validation loss:2.4370133876800537, validation acc: 0.3083333373069763\n",
      "****************************************************************************************************\n",
      "save best model in best_3D_model.pt\n",
      "time:Wed Nov 17 22:03:39 2021, epoch: 10 step: 1, avg running loss is 1.8684648275375366\n",
      "time:Wed Nov 17 22:03:45 2021, epoch: 10 step: 2, avg running loss is 2.141597807407379\n",
      "time:Wed Nov 17 22:03:51 2021, epoch: 10 step: 3, avg running loss is 2.07391885916392\n",
      "time:Wed Nov 17 22:03:56 2021, epoch: 10 step: 4, avg running loss is 2.060273915529251\n",
      "time:Wed Nov 17 22:04:02 2021, epoch: 10 step: 5, avg running loss is 2.0948177099227907\n",
      "time:Wed Nov 17 22:04:08 2021, epoch: 10 step: 6, avg running loss is 2.1056519150733948\n",
      "time:Wed Nov 17 22:04:15 2021, epoch: 10 step: 7, avg running loss is 2.1008069004331316\n",
      "time:Wed Nov 17 22:04:21 2021, epoch: 10 step: 8, avg running loss is 2.1430170089006424\n",
      "time:Wed Nov 17 22:04:27 2021, epoch: 10 step: 9, avg running loss is 2.2051044172710843\n",
      "time:Wed Nov 17 22:04:34 2021, epoch: 10 step: 10, avg running loss is 2.2496129393577577\n",
      "time:Wed Nov 17 22:04:41 2021, epoch: 10 step: 11, avg running loss is 2.2525565082376655\n",
      "time:Wed Nov 17 22:04:47 2021, epoch: 10 step: 12, avg running loss is 2.246513416369756\n",
      "time:Wed Nov 17 22:04:53 2021, epoch: 10 step: 13, avg running loss is 2.2514693461931667\n",
      "time:Wed Nov 17 22:04:58 2021, epoch: 10 step: 14, avg running loss is 2.248572153704507\n",
      "time:Wed Nov 17 22:05:04 2021, epoch: 10 step: 15, avg running loss is 2.259717917442322\n",
      "time:Wed Nov 17 22:05:11 2021, epoch: 10 step: 16, avg running loss is 2.2567609027028084\n",
      "time:Wed Nov 17 22:05:16 2021, epoch: 10 step: 17, avg running loss is 2.245556221288793\n",
      "time:Wed Nov 17 22:05:17 2021, epoch: 10 step: 18, avg running loss is 2.228022297223409\n",
      "****************************************************************************************************\n",
      "epoch: 10, avg training loss:2.228022297223409, avg validation loss:2.460410475730896, validation acc: 0.2750000059604645\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "lowest_loss = 100000000\n",
    "lowest_loss_epoch = 0\n",
    "c = 0\n",
    "patiences = 10\n",
    "for epoch in range(epochs):\n",
    "    running_loss, num_batches = train_process()\n",
    "    test_running_loss, test_num_batches, running_acc = testing_process()\n",
    "    print(\"*\" * 100)\n",
    "    print(\"epoch: {}, avg training loss:{}, avg validation loss:{}, validation acc: {}\".format(epoch + 1,\n",
    "                                                                                               running_loss / num_batches,\n",
    "                                                                                               test_running_loss / test_num_batches,\n",
    "                                                                                               running_acc / test_num_batches))\n",
    "    scheduler.step(test_running_loss / test_num_batches)\n",
    "    print(\"*\" * 100)\n",
    "    # early stopping\n",
    "    if test_running_loss / test_num_batches < lowest_loss:\n",
    "        c = 0\n",
    "        lowest_loss = test_running_loss / test_num_batches\n",
    "        lowest_loss_epoch = epoch\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': lowest_loss,\n",
    "        }, \"best_3D_model.pt\")\n",
    "        print(\"save best model in best_3D_model.pt\")\n",
    "    else:\n",
    "        c += 1\n",
    "    if c == patiences:\n",
    "        print(\"no improvement for {} epochs, model is stopped\".format(patiences))\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## inference process  \n",
    "### load model from check point\n",
    "### do evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VideoModel(\n",
      "  (conv_block_1): Sequential(\n",
      "    (0): Conv3d(3, 32, kernel_size=(3, 3, 2), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "    (1): LeakyReLU(negative_slope=0.01)\n",
      "    (2): Conv3d(32, 32, kernel_size=(3, 3, 2), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "    (3): LeakyReLU(negative_slope=0.01)\n",
      "    (4): MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv_block_2): Sequential(\n",
      "    (0): Conv3d(32, 64, kernel_size=(3, 3, 2), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "    (1): LeakyReLU(negative_slope=0.01)\n",
      "    (2): Conv3d(64, 64, kernel_size=(3, 3, 2), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "    (3): LeakyReLU(negative_slope=0.01)\n",
      "    (4): MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv_block_3): Sequential(\n",
      "    (0): Conv3d(64, 128, kernel_size=(3, 3, 2), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "    (1): LeakyReLU(negative_slope=0.01)\n",
      "    (2): Conv3d(128, 128, kernel_size=(3, 3, 2), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "    (3): LeakyReLU(negative_slope=0.01)\n",
      "    (4): MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv_block_4): Sequential(\n",
      "    (0): Conv3d(128, 256, kernel_size=(3, 3, 2), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "    (1): LeakyReLU(negative_slope=0.01)\n",
      "    (2): Conv3d(256, 256, kernel_size=(3, 3, 2), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "    (3): LeakyReLU(negative_slope=0.01)\n",
      "    (4): MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (lstm_decoder): BidirectionalLSTM(\n",
      "    (rnn): LSTM(5376, 256, batch_first=True, bidirectional=True)\n",
      "    (embedding): Linear(in_features=512, out_features=28, bias=True)\n",
      "  )\n",
      ")\n",
      "Acc in inference process is 0.3083333373069763\n"
     ]
    }
   ],
   "source": [
    "model = VideoModel(number_classes=len(list(char_dict.keys())),\n",
    "                   max_len=6,\n",
    "                   image_shape=image_shape)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "checkpoint = torch.load(\"best_3D_model.pt\")\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "loss = checkpoint['loss']\n",
    "model = model.to(device)\n",
    "print(model)\n",
    "\n",
    "model.eval()\n",
    "acc = 0\n",
    "count = 0\n",
    "with torch.no_grad():\n",
    "    for idx, data in enumerate(test_dataloader):\n",
    "        x, y = data\n",
    "        size = y.size()\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        scores = model(x)\n",
    "\n",
    "        scores = scores.view(size[0] * size[1], -1)\n",
    "        y = y.view(size[0] * size[1])\n",
    "        acc += compute_val_acc(scores, y)\n",
    "        count += 1\n",
    "\n",
    "print(\"Acc in inference process is {}\".format(acc / count))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
