{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## MLP Data Loader\n",
    "\n",
    "\n",
    "The changes fot this data loader is that this dataloader jumps 4 frames for every 5 frames."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import albumentations as A\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import string\n",
    "\n",
    "augmentation = A.Compose([\n",
    "    A.OneOf([\n",
    "        A.IAAAdditiveGaussianNoise(p=0.9),\n",
    "        A.GaussNoise(p=0.9),\n",
    "    ], p=0.9),\n",
    "    A.OneOf([\n",
    "        A.MotionBlur(p=0.9),\n",
    "        A.MedianBlur(blur_limit=3, p=0.9),\n",
    "        A.Blur(blur_limit=4, p=0.9),\n",
    "    ], p=0.9),\n",
    "    A.OneOf([\n",
    "        A.CLAHE(clip_limit=2, p=0.9),\n",
    "        A.Sharpen(p=0.9),\n",
    "        A.Emboss(p=0.9),\n",
    "        A.RandomBrightnessContrast(p=0.95),\n",
    "    ], p=0.9),\n",
    "    A.OneOf(\n",
    "        [\n",
    "            A.HueSaturationValue(p=0.9),\n",
    "            A.RandomGamma(p=0.9),\n",
    "            A.Perspective(p=0.05),\n",
    "        ], p=0.9,\n",
    "    )\n",
    "])\n",
    "\n",
    "\n",
    "def build_transform(shape):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((shape[0], shape[1])),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "    return transform\n",
    "\n",
    "\n",
    "class VideoDataset(Dataset):\n",
    "    def __init__(self, folder_list, char_dict,\n",
    "                 fixed_frame_num=200, fixed_max_len=6,\n",
    "                 image_shape=(100, 100),\n",
    "                 aug=augmentation):\n",
    "        self.folders = folder_list\n",
    "        np.random.shuffle(self.folders)\n",
    "        self.fixed_frame_num = fixed_frame_num\n",
    "        self.char_dict = char_dict\n",
    "        self.fixed_max_len = fixed_max_len\n",
    "        self.augmentation = aug\n",
    "        self.image_shape = image_shape\n",
    "        self.transform = build_transform(shape=self.image_shape)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.folders)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_folder = self.folders[index]\n",
    "        label = image_folder.split(\"/\")[-1].split(\"_\")[-1].strip(\" \")\n",
    "        label_digit = [self.char_dict[i] for i in label]\n",
    "        assert len(label_digit) < self.fixed_max_len\n",
    "        label_digit.append(self.char_dict[\"<eos>\"])\n",
    "        rest = self.fixed_max_len - len(label_digit)\n",
    "        if rest:\n",
    "            label_digit += [self.char_dict[\"<blank>\"]] * rest\n",
    "\n",
    "        image_list = [os.path.join(image_folder, i) for i in os.listdir(image_folder) if i.endswith(\".jpg\")]\n",
    "        image_list = sorted(image_list)\n",
    "        images = []\n",
    "\n",
    "        if len(image_list) >= self.fixed_frame_num:\n",
    "            image_list = image_list[:self.fixed_frame_num]\n",
    "        else:\n",
    "            image_list += [\"pad\"] * (self.fixed_frame_num - len(image_list))\n",
    "\n",
    "        for index,i in enumerate(image_list):\n",
    "            if index%5 == 0:\n",
    "                if i != \"pad\":\n",
    "                    img = Image.open(i).convert(\"RGB\")\n",
    "                    if self.augmentation is not None:\n",
    "                        img = self.augmentation(image=np.array(img, dtype=np.uint8))[\"image\"]\n",
    "                        img = Image.fromarray(img)\n",
    "                else:\n",
    "                    img = Image.new(\"RGB\", (self.image_shape[1], self.image_shape[0]))\n",
    "\n",
    "                img = self.transform(img)\n",
    "\n",
    "                images.append(img)\n",
    "\n",
    "        x = torch.stack(images).flatten()\n",
    "        y = torch.tensor(label_digit, dtype=torch.long)\n",
    "        return x, y"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/allen/anaconda3/envs/pytorch/lib/python3.8/site-packages/albumentations/imgaug/transforms.py:252: FutureWarning: IAAAdditiveGaussianNoise is deprecated. Please use GaussNoise instead\n",
      "  warnings.warn(\"IAAAdditiveGaussianNoise is deprecated. Please use GaussNoise instead\", FutureWarning)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Build MLP + RNN lipsreading  model "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class BidirectionalLSTM(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, nIn, nHidden, nOut):\n",
    "        super(BidirectionalLSTM, self).__init__()\n",
    "\n",
    "        self.rnn = torch.nn.LSTM(nIn, nHidden, bidirectional=True, batch_first=True)\n",
    "        self.embedding = torch.nn.Linear(nHidden * 2, nOut)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        recurrent, _ = self.rnn(inputs)\n",
    "        T, b, h = recurrent.size()\n",
    "        t_rec = recurrent.reshape(T * b, h)\n",
    "        output = self.embedding(t_rec)\n",
    "        output = output.reshape(T, b, -1)\n",
    "        output = F.softmax(output, dim=-1)\n",
    "        return output\n",
    "\n",
    "\n",
    "class VideoModel(torch.nn.Module):\n",
    "    def __init__(self, number_classes=28, max_len=6, image_shape=(100, 100)):\n",
    "        \"\"\"\n",
    "\n",
    "        :param number_classes:\n",
    "        our char dictionary is:\n",
    "        0: <blank>\n",
    "        1: a\n",
    "        2: b\n",
    "        3: c\n",
    "        ...\n",
    "        26: z\n",
    "        27: <eos>\n",
    "        :param max_len: max_len = 6,\n",
    "        Suppose we said abcde,\n",
    "        the the label should be abcde<eos>\n",
    "        abc -> abc<eos><blank><blank>\n",
    "        number_classes = 28, 26 characters + <eos> + <blank>\n",
    "        \"\"\"\n",
    "        super(VideoModel, self).__init__()\n",
    "        self.number_classes = number_classes\n",
    "        self.max_len = max_len\n",
    "        \n",
    "        #MLP processing layer\n",
    "        self.mlp1= self.mlp(432000, 2000)\n",
    "        self.mlp2 = self.mlp(2000,2000)\n",
    "        self.mlp3 = self.mlp(2000, 2000*6)\n",
    "\n",
    "\n",
    "\n",
    "        self.lstm_decoder = BidirectionalLSTM(nIn=2000,\n",
    "                                              nHidden=256,\n",
    "                                              nOut=number_classes)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        #x = x.permute(dims=(0, 2, 3, 4, 1))\n",
    "        x = self.mlp1(x)\n",
    "        x = self.mlp2(x)\n",
    "        x = self.mlp3(x)\n",
    "        shape = x.size()\n",
    "        x = x.view(shape[0], self.max_len, -1)  # bs, max_len, rest\n",
    "\n",
    "        x = self.lstm_decoder(x)\n",
    "        return x\n",
    "\n",
    "    def mlp(self, input_size, output_size):\n",
    "        conv_block = torch.nn.Sequential(\n",
    "            torch.nn.Linear(input_size, output_size),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(output_size, output_size),\n",
    "            torch.nn.ReLU(),\n",
    "        )\n",
    "        return conv_block\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    x = torch.rand(5, 432000)\n",
    "    print('Input shape:', x.shape)\n",
    "    model = VideoModel()\n",
    "    y = model(x)\n",
    "    print('Output shape:',y.size())  # [5, 6, 28]\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Input shape: torch.Size([5, 432000])\n",
      "Output shape: torch.Size([5, 6, 28])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Define the dataloader in this task"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import string\n",
    "import time\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "\n",
    "def make_char_dict():\n",
    "    chars = string.ascii_lowercase\n",
    "    char_dict = {\"<blank>\": 0}\n",
    "    for idx, c in enumerate(chars):\n",
    "        char_dict[c] = idx + 1\n",
    "    current_len = len(list(char_dict.keys()))\n",
    "    char_dict[\"<eos>\"] = current_len\n",
    "    print(char_dict)\n",
    "    return char_dict\n",
    "\n",
    "\n",
    "def get_train_test_folders():\n",
    "    test = open(\"data/eval_lst.txt\", \"r\", encoding=\"utf-8\").readlines()\n",
    "    train = open(\"data/train_lst.txt\", \"r\", encoding=\"utf-8\").readlines()\n",
    "    train_folders = [os.path.join(\"data\", \"data_aligned\", i.strip(\"\\n\")) for i in train]\n",
    "    test_folders = [os.path.join(\"data\", \"data_aligned\", i.strip(\"\\n\")) for i in test]\n",
    "    print(\"train videos:{}\".format(len(train_folders)))\n",
    "    print(\"test videos:{}\".format(len(test_folders)))\n",
    "    return train_folders, test_folders\n",
    "\n",
    "\n",
    "image_shape = (60, 60)\n",
    "\n",
    "char_dict = make_char_dict()\n",
    "train_folders, test_folders = get_train_test_folders()\n",
    "train_dataset = VideoDataset(\n",
    "    folder_list=train_folders,\n",
    "    char_dict=char_dict,\n",
    "    fixed_frame_num=200,\n",
    "    fixed_max_len=6,\n",
    "    image_shape=image_shape,\n",
    ")\n",
    "batch_size = 10\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset, batch_size=batch_size, shuffle=True\n",
    ")\n",
    "test_dataset = VideoDataset(\n",
    "    folder_list=test_folders,\n",
    "    char_dict=char_dict,\n",
    "    fixed_frame_num=200,\n",
    "    fixed_max_len=6,\n",
    "    aug=None,  # No need to do data augmentation in testing dataset\n",
    "    image_shape=image_shape,\n",
    ")\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset, batch_size=batch_size, shuffle=True\n",
    ")\n",
    "\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "cuda\n",
      "{'<blank>': 0, 'a': 1, 'b': 2, 'c': 3, 'd': 4, 'e': 5, 'f': 6, 'g': 7, 'h': 8, 'i': 9, 'j': 10, 'k': 11, 'l': 12, 'm': 13, 'n': 14, 'o': 15, 'p': 16, 'q': 17, 'r': 18, 's': 19, 't': 20, 'u': 21, 'v': 22, 'w': 23, 'x': 24, 'y': 25, 'z': 26, '<eos>': 27}\n",
      "train videos:171\n",
      "test videos:20\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Init our model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "model = VideoModel(number_classes=len(list(char_dict.keys())),\n",
    "                   max_len=6,\n",
    "                   image_shape=image_shape)\n",
    "model = model.to(device)\n",
    "print(model)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "VideoModel(\n",
      "  (mlp1): Sequential(\n",
      "    (0): Linear(in_features=432000, out_features=2000, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=2000, out_features=2000, bias=True)\n",
      "    (3): ReLU()\n",
      "  )\n",
      "  (mlp2): Sequential(\n",
      "    (0): Linear(in_features=2000, out_features=2000, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=2000, out_features=2000, bias=True)\n",
      "    (3): ReLU()\n",
      "  )\n",
      "  (mlp3): Sequential(\n",
      "    (0): Linear(in_features=2000, out_features=12000, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=12000, out_features=12000, bias=True)\n",
      "    (3): ReLU()\n",
      "  )\n",
      "  (lstm_decoder): BidirectionalLSTM(\n",
      "    (rnn): LSTM(2000, 256, batch_first=True, bidirectional=True)\n",
      "    (embedding): Linear(in_features=512, out_features=28, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Setup the loss function and optimizer"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "criterion = torch.nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Setup the training epochs"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# in real traning process, we set 300 epochs with early stopping,\n",
    "# here we just use 10 epochs to show the entire pipeline for your reference\n",
    "epochs = 10  # for easy running"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Setup learning rate scheduler for training"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,\n",
    "                                                       mode='min',\n",
    "                                                       verbose=True,\n",
    "                                                       factor=0.1,\n",
    "                                                       patience=5,\n",
    "                                                       threshold=0.00001)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Define the acc metric function of our task"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "def compute_val_acc(scores, y):\n",
    "    num = scores.size(0)\n",
    "    prediction = scores.argmax(dim=1)\n",
    "    indicator = (prediction == y)\n",
    "    num_matches = indicator.sum()\n",
    "    return num_matches.float() / num"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Summarize the training process as a function"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "def train_process():\n",
    "    running_loss = 0\n",
    "    num_batches = 0\n",
    "\n",
    "    model.train()\n",
    "    for idx, data in enumerate(train_dataloader):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        x, y = data\n",
    "        size = y.size()\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        x.requires_grad_()\n",
    "\n",
    "        scores = model(x)\n",
    "\n",
    "        scores = scores.view(size[0] * size[1], -1)\n",
    "        y = y.view(size[0] * size[1])\n",
    "        loss = criterion(scores, y)\n",
    "\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 5)\n",
    "        optimizer.step()\n",
    "        running_loss += loss.detach().item()\n",
    "        num_batches += 1\n",
    "        print(\"time:{}, epoch: {} step: {}, avg running loss is {}\".format(\n",
    "            time.ctime(), epoch + 1, idx + 1, running_loss / num_batches\n",
    "        ))\n",
    "    return running_loss, num_batches"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## summarize the validation process"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "def testing_process():\n",
    "    running_loss = 0\n",
    "    num_batches = 0\n",
    "    running_acc = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for idx, data in enumerate(test_dataloader):\n",
    "            x, y = data\n",
    "            size = y.size()\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            scores = model(x)\n",
    "\n",
    "            scores = scores.view(size[0] * size[1], -1)\n",
    "            y = y.view(size[0] * size[1])\n",
    "            loss = criterion(scores, y)\n",
    "            running_loss += loss.item()\n",
    "            num_batches += 1\n",
    "            running_acc += compute_val_acc(scores, y)\n",
    "    return running_loss, num_batches, running_acc\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training and evaluate models for each epoch  \n",
    "#### plus: using learning rate scheduler to improve the performance\n",
    "#### plus: using early stopping for real training task to avoid over-fitting"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "lowest_loss = 100000000\n",
    "lowest_loss_epoch = 0\n",
    "c = 0\n",
    "patiences = 10\n",
    "for epoch in range(epochs):\n",
    "    running_loss, num_batches = train_process()\n",
    "    test_running_loss, test_num_batches, running_acc = testing_process()\n",
    "    print(\"*\" * 100)\n",
    "    print(\"epoch: {}, avg training loss:{}, avg validation loss:{}, validation acc: {}\".format(epoch + 1,\n",
    "                                                                                               running_loss / num_batches,\n",
    "                                                                                               test_running_loss / test_num_batches,\n",
    "                                                                                               running_acc / test_num_batches))\n",
    "    scheduler.step(test_running_loss / test_num_batches)\n",
    "    print(\"*\" * 100)\n",
    "    # early stopping\n",
    "    if test_running_loss / test_num_batches < lowest_loss:\n",
    "        c = 0\n",
    "        lowest_loss = test_running_loss / test_num_batches\n",
    "        lowest_loss_epoch = epoch\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': lowest_loss,\n",
    "        }, \"best_mlp_model.pt\")\n",
    "        print(\"save best model in best_mlp_model.pt\")\n",
    "    else:\n",
    "        c += 1\n",
    "    if c == patiences:\n",
    "        print(\"no improvement for {} epochs, model is stopped\".format(patiences))\n",
    "        break"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "time:Wed Nov 17 23:26:49 2021, epoch: 1 step: 1, avg running loss is 3.332216739654541\n",
      "time:Wed Nov 17 23:26:56 2021, epoch: 1 step: 2, avg running loss is 3.332311749458313\n",
      "time:Wed Nov 17 23:27:04 2021, epoch: 1 step: 3, avg running loss is 3.3322948614756265\n",
      "time:Wed Nov 17 23:27:09 2021, epoch: 1 step: 4, avg running loss is 3.332262933254242\n",
      "time:Wed Nov 17 23:27:15 2021, epoch: 1 step: 5, avg running loss is 3.332238960266113\n",
      "time:Wed Nov 17 23:27:20 2021, epoch: 1 step: 6, avg running loss is 3.3322213888168335\n",
      "time:Wed Nov 17 23:27:26 2021, epoch: 1 step: 7, avg running loss is 3.3321676594870433\n",
      "time:Wed Nov 17 23:27:33 2021, epoch: 1 step: 8, avg running loss is 3.332140177488327\n",
      "time:Wed Nov 17 23:27:39 2021, epoch: 1 step: 9, avg running loss is 3.3320784833696155\n",
      "time:Wed Nov 17 23:27:46 2021, epoch: 1 step: 10, avg running loss is 3.33204185962677\n",
      "time:Wed Nov 17 23:27:50 2021, epoch: 1 step: 11, avg running loss is 3.3320165764201772\n",
      "time:Wed Nov 17 23:27:56 2021, epoch: 1 step: 12, avg running loss is 3.331962446371714\n",
      "time:Wed Nov 17 23:28:01 2021, epoch: 1 step: 13, avg running loss is 3.3319002848405104\n",
      "time:Wed Nov 17 23:28:06 2021, epoch: 1 step: 14, avg running loss is 3.3318377562931607\n",
      "time:Wed Nov 17 23:28:10 2021, epoch: 1 step: 15, avg running loss is 3.3317592620849608\n",
      "time:Wed Nov 17 23:28:15 2021, epoch: 1 step: 16, avg running loss is 3.3316659033298492\n",
      "time:Wed Nov 17 23:28:20 2021, epoch: 1 step: 17, avg running loss is 3.331600175184362\n",
      "time:Wed Nov 17 23:28:20 2021, epoch: 1 step: 18, avg running loss is 3.3315924406051636\n",
      "****************************************************************************************************\n",
      "epoch: 1, avg training loss:3.3315924406051636, avg validation loss:3.330241322517395, validation acc: 0.28333336114883423\n",
      "****************************************************************************************************\n",
      "save best model in best_mlp_model.pt\n",
      "time:Wed Nov 17 23:29:54 2021, epoch: 2 step: 1, avg running loss is 3.329615354537964\n",
      "time:Wed Nov 17 23:29:55 2021, epoch: 2 step: 2, avg running loss is 3.32968807220459\n",
      "time:Wed Nov 17 23:29:55 2021, epoch: 2 step: 3, avg running loss is 3.3295880953470864\n",
      "time:Wed Nov 17 23:29:56 2021, epoch: 2 step: 4, avg running loss is 3.3296634554862976\n",
      "time:Wed Nov 17 23:29:57 2021, epoch: 2 step: 5, avg running loss is 3.3296562671661376\n",
      "time:Wed Nov 17 23:29:57 2021, epoch: 2 step: 6, avg running loss is 3.3297164042790732\n",
      "time:Wed Nov 17 23:29:58 2021, epoch: 2 step: 7, avg running loss is 3.329606601170131\n",
      "time:Wed Nov 17 23:29:59 2021, epoch: 2 step: 8, avg running loss is 3.329465836286545\n",
      "time:Wed Nov 17 23:29:59 2021, epoch: 2 step: 9, avg running loss is 3.3293004035949707\n",
      "time:Wed Nov 17 23:30:00 2021, epoch: 2 step: 10, avg running loss is 3.3291429042816163\n",
      "time:Wed Nov 17 23:30:01 2021, epoch: 2 step: 11, avg running loss is 3.3290293433449487\n",
      "time:Wed Nov 17 23:30:01 2021, epoch: 2 step: 12, avg running loss is 3.3288396199544272\n",
      "time:Wed Nov 17 23:30:02 2021, epoch: 2 step: 13, avg running loss is 3.3286868792313795\n",
      "time:Wed Nov 17 23:30:02 2021, epoch: 2 step: 14, avg running loss is 3.3283645766122\n",
      "time:Wed Nov 17 23:30:03 2021, epoch: 2 step: 15, avg running loss is 3.328169345855713\n",
      "time:Wed Nov 17 23:30:04 2021, epoch: 2 step: 16, avg running loss is 3.3280687779188156\n",
      "time:Wed Nov 17 23:30:04 2021, epoch: 2 step: 17, avg running loss is 3.3279354712542366\n",
      "time:Wed Nov 17 23:30:04 2021, epoch: 2 step: 18, avg running loss is 3.3277842071321277\n",
      "****************************************************************************************************\n",
      "epoch: 2, avg training loss:3.3277842071321277, avg validation loss:3.3257635831832886, validation acc: 0.28333336114883423\n",
      "****************************************************************************************************\n",
      "save best model in best_mlp_model.pt\n",
      "time:Wed Nov 17 23:31:25 2021, epoch: 3 step: 1, avg running loss is 3.324068307876587\n",
      "time:Wed Nov 17 23:31:25 2021, epoch: 3 step: 2, avg running loss is 3.323234438896179\n",
      "time:Wed Nov 17 23:31:26 2021, epoch: 3 step: 3, avg running loss is 3.3236963748931885\n",
      "time:Wed Nov 17 23:31:27 2021, epoch: 3 step: 4, avg running loss is 3.324277400970459\n",
      "time:Wed Nov 17 23:31:27 2021, epoch: 3 step: 5, avg running loss is 3.324595308303833\n",
      "time:Wed Nov 17 23:31:28 2021, epoch: 3 step: 6, avg running loss is 3.3236956199010215\n",
      "time:Wed Nov 17 23:31:29 2021, epoch: 3 step: 7, avg running loss is 3.3235153470720564\n",
      "time:Wed Nov 17 23:31:29 2021, epoch: 3 step: 8, avg running loss is 3.3234164714813232\n",
      "time:Wed Nov 17 23:31:30 2021, epoch: 3 step: 9, avg running loss is 3.32302196820577\n",
      "time:Wed Nov 17 23:31:31 2021, epoch: 3 step: 10, avg running loss is 3.322692704200745\n",
      "time:Wed Nov 17 23:31:31 2021, epoch: 3 step: 11, avg running loss is 3.3224733526056465\n",
      "time:Wed Nov 17 23:31:32 2021, epoch: 3 step: 12, avg running loss is 3.3221378525098166\n",
      "time:Wed Nov 17 23:31:33 2021, epoch: 3 step: 13, avg running loss is 3.321769200838529\n",
      "time:Wed Nov 17 23:31:33 2021, epoch: 3 step: 14, avg running loss is 3.321721519742693\n",
      "time:Wed Nov 17 23:31:34 2021, epoch: 3 step: 15, avg running loss is 3.321352163950602\n",
      "time:Wed Nov 17 23:31:35 2021, epoch: 3 step: 16, avg running loss is 3.3207415491342545\n",
      "time:Wed Nov 17 23:31:35 2021, epoch: 3 step: 17, avg running loss is 3.3200518523945526\n",
      "time:Wed Nov 17 23:31:35 2021, epoch: 3 step: 18, avg running loss is 3.3206940491994223\n",
      "****************************************************************************************************\n",
      "epoch: 3, avg training loss:3.3206940491994223, avg validation loss:3.314820170402527, validation acc: 0.28333336114883423\n",
      "****************************************************************************************************\n",
      "save best model in best_mlp_model.pt\n",
      "time:Wed Nov 17 23:33:00 2021, epoch: 4 step: 1, avg running loss is 3.3089818954467773\n",
      "time:Wed Nov 17 23:33:01 2021, epoch: 4 step: 2, avg running loss is 3.3102627992630005\n",
      "time:Wed Nov 17 23:33:01 2021, epoch: 4 step: 3, avg running loss is 3.3104196389516196\n",
      "time:Wed Nov 17 23:33:02 2021, epoch: 4 step: 4, avg running loss is 3.308993339538574\n",
      "time:Wed Nov 17 23:33:02 2021, epoch: 4 step: 5, avg running loss is 3.3065678596496584\n",
      "time:Wed Nov 17 23:33:03 2021, epoch: 4 step: 6, avg running loss is 3.3052037954330444\n",
      "time:Wed Nov 17 23:33:04 2021, epoch: 4 step: 7, avg running loss is 3.3048856939588274\n",
      "time:Wed Nov 17 23:33:04 2021, epoch: 4 step: 8, avg running loss is 3.3022600412368774\n",
      "time:Wed Nov 17 23:33:05 2021, epoch: 4 step: 9, avg running loss is 3.2997603946261935\n",
      "time:Wed Nov 17 23:33:05 2021, epoch: 4 step: 10, avg running loss is 3.2946449518203735\n",
      "time:Wed Nov 17 23:33:06 2021, epoch: 4 step: 11, avg running loss is 3.2847209626978096\n",
      "time:Wed Nov 17 23:33:07 2021, epoch: 4 step: 12, avg running loss is 3.274265686670939\n",
      "time:Wed Nov 17 23:33:07 2021, epoch: 4 step: 13, avg running loss is 3.262288808822632\n",
      "time:Wed Nov 17 23:33:08 2021, epoch: 4 step: 14, avg running loss is 3.243225199835641\n",
      "time:Wed Nov 17 23:33:08 2021, epoch: 4 step: 15, avg running loss is 3.2278743584950766\n",
      "time:Wed Nov 17 23:33:09 2021, epoch: 4 step: 16, avg running loss is 3.217431515455246\n",
      "time:Wed Nov 17 23:33:09 2021, epoch: 4 step: 17, avg running loss is 3.2069712526658\n",
      "time:Wed Nov 17 23:33:10 2021, epoch: 4 step: 18, avg running loss is 3.1883988115522595\n",
      "****************************************************************************************************\n",
      "epoch: 4, avg training loss:3.1883988115522595, avg validation loss:3.0868406295776367, validation acc: 0.3166666626930237\n",
      "****************************************************************************************************\n",
      "save best model in best_mlp_model.pt\n",
      "time:Wed Nov 17 23:34:26 2021, epoch: 5 step: 1, avg running loss is 3.070838212966919\n",
      "time:Wed Nov 17 23:34:26 2021, epoch: 5 step: 2, avg running loss is 3.0361894369125366\n",
      "time:Wed Nov 17 23:34:27 2021, epoch: 5 step: 3, avg running loss is 3.0739285151163735\n",
      "time:Wed Nov 17 23:34:28 2021, epoch: 5 step: 4, avg running loss is 3.054061710834503\n",
      "time:Wed Nov 17 23:34:28 2021, epoch: 5 step: 5, avg running loss is 3.0422462463378905\n",
      "time:Wed Nov 17 23:34:29 2021, epoch: 5 step: 6, avg running loss is 3.0335445006688437\n",
      "time:Wed Nov 17 23:34:29 2021, epoch: 5 step: 7, avg running loss is 3.029939923967634\n",
      "time:Wed Nov 17 23:34:30 2021, epoch: 5 step: 8, avg running loss is 3.0321227610111237\n",
      "time:Wed Nov 17 23:34:30 2021, epoch: 5 step: 9, avg running loss is 3.035695923699273\n",
      "time:Wed Nov 17 23:34:31 2021, epoch: 5 step: 10, avg running loss is 3.0282164812088013\n",
      "time:Wed Nov 17 23:34:32 2021, epoch: 5 step: 11, avg running loss is 3.025341033935547\n",
      "time:Wed Nov 17 23:34:32 2021, epoch: 5 step: 12, avg running loss is 3.027471582094828\n",
      "time:Wed Nov 17 23:34:33 2021, epoch: 5 step: 13, avg running loss is 3.01883105131296\n",
      "time:Wed Nov 17 23:34:33 2021, epoch: 5 step: 14, avg running loss is 3.0210810899734497\n",
      "time:Wed Nov 17 23:34:34 2021, epoch: 5 step: 15, avg running loss is 3.031694253285726\n",
      "time:Wed Nov 17 23:34:35 2021, epoch: 5 step: 16, avg running loss is 3.0203876942396164\n",
      "time:Wed Nov 17 23:34:35 2021, epoch: 5 step: 17, avg running loss is 3.023990042069379\n",
      "time:Wed Nov 17 23:34:35 2021, epoch: 5 step: 18, avg running loss is 3.034654484854804\n",
      "****************************************************************************************************\n",
      "epoch: 5, avg training loss:3.034654484854804, avg validation loss:3.090204954147339, validation acc: 0.2916666865348816\n",
      "****************************************************************************************************\n",
      "time:Wed Nov 17 23:34:36 2021, epoch: 6 step: 1, avg running loss is 3.1309654712677\n",
      "time:Wed Nov 17 23:34:37 2021, epoch: 6 step: 2, avg running loss is 3.089808940887451\n",
      "time:Wed Nov 17 23:34:38 2021, epoch: 6 step: 3, avg running loss is 3.081226030985514\n",
      "time:Wed Nov 17 23:34:38 2021, epoch: 6 step: 4, avg running loss is 3.0515055656433105\n",
      "time:Wed Nov 17 23:34:39 2021, epoch: 6 step: 5, avg running loss is 3.047251510620117\n",
      "time:Wed Nov 17 23:34:39 2021, epoch: 6 step: 6, avg running loss is 3.031048854192098\n",
      "time:Wed Nov 17 23:34:40 2021, epoch: 6 step: 7, avg running loss is 3.0384341308048795\n",
      "time:Wed Nov 17 23:34:41 2021, epoch: 6 step: 8, avg running loss is 3.0232203602790833\n",
      "time:Wed Nov 17 23:34:41 2021, epoch: 6 step: 9, avg running loss is 3.018693447113037\n",
      "time:Wed Nov 17 23:34:42 2021, epoch: 6 step: 10, avg running loss is 3.0164935111999513\n",
      "time:Wed Nov 17 23:34:42 2021, epoch: 6 step: 11, avg running loss is 3.028300068595193\n",
      "time:Wed Nov 17 23:34:43 2021, epoch: 6 step: 12, avg running loss is 3.0134230653444924\n",
      "time:Wed Nov 17 23:34:44 2021, epoch: 6 step: 13, avg running loss is 3.0108938950758715\n",
      "time:Wed Nov 17 23:34:44 2021, epoch: 6 step: 14, avg running loss is 3.0182326350893294\n",
      "time:Wed Nov 17 23:34:45 2021, epoch: 6 step: 15, avg running loss is 3.0169329484303793\n",
      "time:Wed Nov 17 23:34:45 2021, epoch: 6 step: 16, avg running loss is 3.013717383146286\n",
      "time:Wed Nov 17 23:34:46 2021, epoch: 6 step: 17, avg running loss is 3.012679941513959\n",
      "time:Wed Nov 17 23:34:46 2021, epoch: 6 step: 18, avg running loss is 3.0147921641667685\n",
      "****************************************************************************************************\n",
      "epoch: 6, avg training loss:3.0147921641667685, avg validation loss:3.0905829668045044, validation acc: 0.2916666865348816\n",
      "****************************************************************************************************\n",
      "time:Wed Nov 17 23:34:47 2021, epoch: 7 step: 1, avg running loss is 3.0825281143188477\n",
      "time:Wed Nov 17 23:34:48 2021, epoch: 7 step: 2, avg running loss is 3.096378803253174\n",
      "time:Wed Nov 17 23:34:48 2021, epoch: 7 step: 3, avg running loss is 3.0742685794830322\n",
      "time:Wed Nov 17 23:34:49 2021, epoch: 7 step: 4, avg running loss is 3.063645362854004\n",
      "time:Wed Nov 17 23:34:49 2021, epoch: 7 step: 5, avg running loss is 3.0135644912719726\n",
      "time:Wed Nov 17 23:34:50 2021, epoch: 7 step: 6, avg running loss is 3.024083971977234\n",
      "time:Wed Nov 17 23:34:50 2021, epoch: 7 step: 7, avg running loss is 3.0110570022038052\n",
      "time:Wed Nov 17 23:34:51 2021, epoch: 7 step: 8, avg running loss is 3.005417585372925\n",
      "time:Wed Nov 17 23:34:52 2021, epoch: 7 step: 9, avg running loss is 3.01172227329678\n",
      "time:Wed Nov 17 23:34:52 2021, epoch: 7 step: 10, avg running loss is 3.020055055618286\n",
      "time:Wed Nov 17 23:34:53 2021, epoch: 7 step: 11, avg running loss is 3.0136317123066294\n",
      "time:Wed Nov 17 23:34:53 2021, epoch: 7 step: 12, avg running loss is 3.008396009604136\n",
      "time:Wed Nov 17 23:34:54 2021, epoch: 7 step: 13, avg running loss is 3.0128069657545824\n",
      "time:Wed Nov 17 23:34:55 2021, epoch: 7 step: 14, avg running loss is 3.0106814418520247\n",
      "time:Wed Nov 17 23:34:55 2021, epoch: 7 step: 15, avg running loss is 3.011933517456055\n",
      "time:Wed Nov 17 23:34:56 2021, epoch: 7 step: 16, avg running loss is 3.014299049973488\n",
      "time:Wed Nov 17 23:34:56 2021, epoch: 7 step: 17, avg running loss is 3.014229550081141\n",
      "time:Wed Nov 17 23:34:57 2021, epoch: 7 step: 18, avg running loss is 2.997860802544488\n",
      "****************************************************************************************************\n",
      "epoch: 7, avg training loss:2.997860802544488, avg validation loss:3.0909515619277954, validation acc: 0.2916666865348816\n",
      "****************************************************************************************************\n",
      "time:Wed Nov 17 23:34:57 2021, epoch: 8 step: 1, avg running loss is 2.916212558746338\n",
      "time:Wed Nov 17 23:34:58 2021, epoch: 8 step: 2, avg running loss is 2.974549174308777\n",
      "time:Wed Nov 17 23:34:59 2021, epoch: 8 step: 3, avg running loss is 2.999145030975342\n",
      "time:Wed Nov 17 23:34:59 2021, epoch: 8 step: 4, avg running loss is 3.0067445635795593\n",
      "time:Wed Nov 17 23:35:00 2021, epoch: 8 step: 5, avg running loss is 3.0119780540466308\n",
      "time:Wed Nov 17 23:35:00 2021, epoch: 8 step: 6, avg running loss is 3.025961915651957\n",
      "time:Wed Nov 17 23:35:01 2021, epoch: 8 step: 7, avg running loss is 3.0268121787479947\n",
      "time:Wed Nov 17 23:35:02 2021, epoch: 8 step: 8, avg running loss is 3.023095518350601\n",
      "time:Wed Nov 17 23:35:02 2021, epoch: 8 step: 9, avg running loss is 3.0164455572764077\n",
      "time:Wed Nov 17 23:35:03 2021, epoch: 8 step: 10, avg running loss is 3.01804358959198\n",
      "time:Wed Nov 17 23:35:03 2021, epoch: 8 step: 11, avg running loss is 3.025129556655884\n",
      "time:Wed Nov 17 23:35:04 2021, epoch: 8 step: 12, avg running loss is 3.0104190905888877\n",
      "time:Wed Nov 17 23:35:05 2021, epoch: 8 step: 13, avg running loss is 3.0144176483154297\n",
      "time:Wed Nov 17 23:35:05 2021, epoch: 8 step: 14, avg running loss is 3.0192465611866544\n",
      "time:Wed Nov 17 23:35:06 2021, epoch: 8 step: 15, avg running loss is 3.0177874088287355\n",
      "time:Wed Nov 17 23:35:06 2021, epoch: 8 step: 16, avg running loss is 3.011033296585083\n",
      "time:Wed Nov 17 23:35:07 2021, epoch: 8 step: 17, avg running loss is 3.0141115188598633\n",
      "time:Wed Nov 17 23:35:07 2021, epoch: 8 step: 18, avg running loss is 2.9977214203940497\n",
      "****************************************************************************************************\n",
      "epoch: 8, avg training loss:2.9977214203940497, avg validation loss:3.090463876724243, validation acc: 0.2916666865348816\n",
      "****************************************************************************************************\n",
      "time:Wed Nov 17 23:35:08 2021, epoch: 9 step: 1, avg running loss is 2.946040391921997\n",
      "time:Wed Nov 17 23:35:08 2021, epoch: 9 step: 2, avg running loss is 2.9639812707901\n",
      "time:Wed Nov 17 23:35:09 2021, epoch: 9 step: 3, avg running loss is 2.9759305318196616\n",
      "time:Wed Nov 17 23:35:10 2021, epoch: 9 step: 4, avg running loss is 2.9734309315681458\n",
      "time:Wed Nov 17 23:35:10 2021, epoch: 9 step: 5, avg running loss is 2.9813488483428956\n",
      "time:Wed Nov 17 23:35:11 2021, epoch: 9 step: 6, avg running loss is 2.9784619410832724\n",
      "time:Wed Nov 17 23:35:11 2021, epoch: 9 step: 7, avg running loss is 2.9738052572522844\n",
      "time:Wed Nov 17 23:35:12 2021, epoch: 9 step: 8, avg running loss is 2.9807024598121643\n",
      "time:Wed Nov 17 23:35:13 2021, epoch: 9 step: 9, avg running loss is 2.997504631678263\n",
      "time:Wed Nov 17 23:35:13 2021, epoch: 9 step: 10, avg running loss is 2.9960787534713744\n",
      "time:Wed Nov 17 23:35:14 2021, epoch: 9 step: 11, avg running loss is 2.991703163493763\n",
      "time:Wed Nov 17 23:35:15 2021, epoch: 9 step: 12, avg running loss is 2.994985262552897\n",
      "time:Wed Nov 17 23:35:15 2021, epoch: 9 step: 13, avg running loss is 2.9976430856264553\n",
      "time:Wed Nov 17 23:35:16 2021, epoch: 9 step: 14, avg running loss is 3.00230188029153\n",
      "time:Wed Nov 17 23:35:16 2021, epoch: 9 step: 15, avg running loss is 2.999403715133667\n",
      "time:Wed Nov 17 23:35:17 2021, epoch: 9 step: 16, avg running loss is 3.004277765750885\n",
      "time:Wed Nov 17 23:35:18 2021, epoch: 9 step: 17, avg running loss is 3.009942896225873\n",
      "time:Wed Nov 17 23:35:18 2021, epoch: 9 step: 18, avg running loss is 3.0306784179475574\n",
      "****************************************************************************************************\n",
      "epoch: 9, avg training loss:3.0306784179475574, avg validation loss:3.0906081199645996, validation acc: 0.2916666865348816\n",
      "****************************************************************************************************\n",
      "time:Wed Nov 17 23:35:19 2021, epoch: 10 step: 1, avg running loss is 3.098400354385376\n",
      "time:Wed Nov 17 23:35:19 2021, epoch: 10 step: 2, avg running loss is 3.0638574361801147\n",
      "time:Wed Nov 17 23:35:20 2021, epoch: 10 step: 3, avg running loss is 3.0313560962677\n",
      "time:Wed Nov 17 23:35:20 2021, epoch: 10 step: 4, avg running loss is 3.002955436706543\n",
      "time:Wed Nov 17 23:35:21 2021, epoch: 10 step: 5, avg running loss is 3.005366849899292\n",
      "time:Wed Nov 17 23:35:21 2021, epoch: 10 step: 6, avg running loss is 2.9847222566604614\n",
      "time:Wed Nov 17 23:35:22 2021, epoch: 10 step: 7, avg running loss is 3.0004397119794572\n",
      "time:Wed Nov 17 23:35:23 2021, epoch: 10 step: 8, avg running loss is 3.000399261713028\n",
      "time:Wed Nov 17 23:35:23 2021, epoch: 10 step: 9, avg running loss is 3.0036084916856556\n",
      "time:Wed Nov 17 23:35:24 2021, epoch: 10 step: 10, avg running loss is 3.0060682773590086\n",
      "time:Wed Nov 17 23:35:24 2021, epoch: 10 step: 11, avg running loss is 3.0069274468855425\n",
      "time:Wed Nov 17 23:35:25 2021, epoch: 10 step: 12, avg running loss is 2.993720531463623\n",
      "time:Wed Nov 17 23:35:26 2021, epoch: 10 step: 13, avg running loss is 2.9990920286912184\n",
      "time:Wed Nov 17 23:35:26 2021, epoch: 10 step: 14, avg running loss is 3.004735623087202\n",
      "time:Wed Nov 17 23:35:27 2021, epoch: 10 step: 15, avg running loss is 3.010853560765584\n",
      "time:Wed Nov 17 23:35:27 2021, epoch: 10 step: 16, avg running loss is 3.008726626634598\n",
      "time:Wed Nov 17 23:35:28 2021, epoch: 10 step: 17, avg running loss is 3.013740427353803\n",
      "time:Wed Nov 17 23:35:28 2021, epoch: 10 step: 18, avg running loss is 2.9972943200005426\n",
      "****************************************************************************************************\n",
      "epoch: 10, avg training loss:2.9972943200005426, avg validation loss:3.0904942750930786, validation acc: 0.2916666865348816\n",
      "Epoch    10: reducing learning rate of group 0 to 1.0000e-02.\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Inference process  \n",
    "### load model from check point\n",
    "### do evaluation \n",
    "### the trained model is too big for this case, we will not uploaed"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "model = VideoModel(number_classes=len(list(char_dict.keys())),\n",
    "                   max_len=6,\n",
    "                   image_shape=image_shape)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "checkpoint = torch.load(\"best_mlp_model.pt\")\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "loss = checkpoint['loss']\n",
    "model = model.to(device)\n",
    "print(model)\n",
    "\n",
    "model.eval()\n",
    "acc = 0\n",
    "count = 0\n",
    "with torch.no_grad():\n",
    "    for idx, data in enumerate(test_dataloader):\n",
    "        x, y = data\n",
    "        size = y.size()\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        scores = model(x)\n",
    "\n",
    "        scores = scores.view(size[0] * size[1], -1)\n",
    "        y = y.view(size[0] * size[1])\n",
    "        acc += compute_val_acc(scores, y)\n",
    "        count += 1\n",
    "\n",
    "print(\"Acc in inference process is {}\".format(acc / count))\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "VideoModel(\n",
      "  (mlp1): Sequential(\n",
      "    (0): Linear(in_features=432000, out_features=2000, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=2000, out_features=2000, bias=True)\n",
      "    (3): ReLU()\n",
      "  )\n",
      "  (mlp2): Sequential(\n",
      "    (0): Linear(in_features=2000, out_features=2000, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=2000, out_features=2000, bias=True)\n",
      "    (3): ReLU()\n",
      "  )\n",
      "  (mlp3): Sequential(\n",
      "    (0): Linear(in_features=2000, out_features=12000, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=12000, out_features=12000, bias=True)\n",
      "    (3): ReLU()\n",
      "  )\n",
      "  (lstm_decoder): BidirectionalLSTM(\n",
      "    (rnn): LSTM(2000, 256, batch_first=True, bidirectional=True)\n",
      "    (embedding): Linear(in_features=512, out_features=28, bias=True)\n",
      "  )\n",
      ")\n",
      "Acc in inference process is 0.31666669249534607\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "331356ca85e702178c703a299ac9d9de723919524fe12d97979a0dacce9e25f6"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('pytorch': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}