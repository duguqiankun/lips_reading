{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "520cf4f1",
   "metadata": {},
   "source": [
    "# Define Concatenation Image Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d05404d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import albumentations as A\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import string\n",
    "import math\n",
    "\n",
    "augmentation = A.Compose([\n",
    "    A.OneOf([\n",
    "        A.IAAAdditiveGaussianNoise(p=0.9),\n",
    "        A.GaussNoise(p=0.9),\n",
    "    ], p=0.9),\n",
    "    A.OneOf([\n",
    "        A.MotionBlur(p=0.9),\n",
    "        A.MedianBlur(blur_limit=3, p=0.9),\n",
    "        A.Blur(blur_limit=4, p=0.9),\n",
    "    ], p=0.9),\n",
    "    A.OneOf([\n",
    "        A.CLAHE(clip_limit=2, p=0.9),\n",
    "        A.IAASharpen(p=0.9),\n",
    "        A.IAAEmboss(p=0.9),\n",
    "        A.RandomBrightnessContrast(p=0.95),\n",
    "    ], p=0.9),\n",
    "    A.OneOf(\n",
    "        [\n",
    "            A.HueSaturationValue(p=0.9),\n",
    "            A.RandomGamma(p=0.9),\n",
    "            A.IAAPerspective(p=0.05),\n",
    "        ], p=0.9,\n",
    "    )\n",
    "])\n",
    "\n",
    "\n",
    "def build_transform(shape):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "    return transform\n",
    "\n",
    "\n",
    "class VideoDataset(Dataset):\n",
    "    def __init__(self, folder_list, char_dict,\n",
    "                 fixed_frame_num=200, fixed_max_len=6,\n",
    "                 image_shape=(100, 100),\n",
    "                 aug=augmentation):\n",
    "        self.folders = folder_list\n",
    "        np.random.shuffle(self.folders)\n",
    "        self.fixed_frame_num = fixed_frame_num\n",
    "        self.char_dict = char_dict\n",
    "        self.fixed_max_len = fixed_max_len\n",
    "        self.augmentation = aug\n",
    "        self.image_shape = image_shape\n",
    "        self.transform = build_transform(shape=self.image_shape)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.folders)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_folder = self.folders[index]\n",
    "        label = image_folder.split(\"/\")[-1].split(\"_\")[-1].strip(\" \")\n",
    "        label_digit = [self.char_dict[i] for i in label]\n",
    "        assert len(label_digit) < self.fixed_max_len\n",
    "        label_digit.append(self.char_dict[\"<eos>\"])\n",
    "        rest = self.fixed_max_len - len(label_digit)\n",
    "        if rest:\n",
    "            label_digit += [self.char_dict[\"<blank>\"]] * rest\n",
    "\n",
    "        image_list = [os.path.join(image_folder, i) for i in os.listdir(image_folder) if i.endswith(\".jpg\")]\n",
    "        image_list = sorted(image_list)\n",
    "        images = []\n",
    "        \n",
    "        k_col, k_row = 4, 4\n",
    "        max_frame_num = k_col * k_row\n",
    "\n",
    "        if len(image_list) <= max_frame_num:\n",
    "            image_list += [\"pad\"] * (max_frame_num - len(image_list))\n",
    "        \n",
    "        k_frame_pick_one = math.floor(len(image_list) / (k_col * k_row))\n",
    "        \n",
    "        # print('k_frame_pick_one: ', k_frame_pick_one)\n",
    "\n",
    "        for index,i in enumerate(image_list):\n",
    "            if index%k_frame_pick_one == 0:\n",
    "                if i != \"pad\":\n",
    "                    img = Image.open(i).convert(\"RGB\")\n",
    "                    if self.augmentation is not None:\n",
    "                        img = self.augmentation(image=np.array(img, dtype=np.uint8))[\"image\"]\n",
    "                        img = Image.fromarray(img)\n",
    "                else:\n",
    "                    img = Image.new(\"RGB\", (self.image_shape[1], self.image_shape[0]))\n",
    "\n",
    "                img = img.resize(self.image_shape)\n",
    "                images.append(img)\n",
    "\n",
    "        x = Image.new('RGB', (self.image_shape[1] * k_row, self.image_shape[0] * k_col))\n",
    "\n",
    "        for i in range(k_col):\n",
    "            for k in range(k_row):\n",
    "                x.paste(images[i * k_col + k], (self.image_shape[1] * k, self.image_shape[0] * i))\n",
    "        \n",
    "\n",
    "        x.save('./test.jpg', quality=50)\n",
    "\n",
    "        x = self.transform(x)\n",
    "        y = torch.tensor(label_digit, dtype=torch.long)\n",
    "        \n",
    "        return x, y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a16904d",
   "metadata": {},
   "source": [
    "# Build 2DCNN + RNN lipsreading model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17a380ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class BidirectionalLSTM(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, nIn, nHidden, nOut):\n",
    "        super(BidirectionalLSTM, self).__init__()\n",
    "\n",
    "        self.rnn = torch.nn.LSTM(nIn, nHidden, bidirectional=True, batch_first=True)\n",
    "        self.embedding = torch.nn.Linear(nHidden * 2, nOut)\n",
    "        # self.embedding_1 = torch.nn.Linear(nHidden * 2, nHidden)\n",
    "        # self.embedding_2 = torch.nn.Linear(nHidden, nHidden//2)\n",
    "        # self.embedding_3 = torch.nn.Linear(nHidden//2, nOut)\n",
    "        # self.dropout_1 = torch.nn.Dropout(p=0.1)\n",
    "        # self.dropout_2 = torch.nn.Dropout(p=0.25)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        recurrent, _ = self.rnn(inputs)\n",
    "        T, b, h = recurrent.size()\n",
    "        t_rec = recurrent.reshape(T * b, h)\n",
    "\n",
    "        # output = self.embedding_1(t_rec)  # [T * b, nOut]\n",
    "        # output = self.dropout_1(output)\n",
    "        # output = F.relu(output)\n",
    "        #\n",
    "        # output = self.embedding_2(output)\n",
    "        # # output = self.dropout_2(output)\n",
    "        # output = F.relu(output)\n",
    "        #\n",
    "        # output = self.embedding_3(output)\n",
    "\n",
    "        output = self.embedding(t_rec)\n",
    "\n",
    "        output = output.reshape(T, b, -1)\n",
    "        # output = F.softmax(output, dim=-1)\n",
    "        return output\n",
    "\n",
    "\n",
    "class VideoModel(torch.nn.Module):\n",
    "    def __init__(self, number_classes=28, max_len=6, image_shape=(60, 60)):\n",
    "        \"\"\"\n",
    "\n",
    "        :param number_classes:\n",
    "        our char dictionary is:\n",
    "        0: <blank>\n",
    "        1: a\n",
    "        2: b\n",
    "        3: c\n",
    "        ...\n",
    "        26: z\n",
    "        27: <eos>\n",
    "        :param max_len: max_len = 6,\n",
    "        Suppose we said abcde,\n",
    "        the the label should be abcde<eos>\n",
    "        abc -> abc<eos><blank><blank>\n",
    "        number_classes = 28, 26 characters + <eos> + <blank>\n",
    "        \"\"\"\n",
    "        super(VideoModel, self).__init__()\n",
    "        self.number_classes = number_classes\n",
    "        self.max_len = max_len\n",
    "        \n",
    "        self.conv_block_1 = self. _cnn2d_block_2_conv_layer(3, 32)\n",
    "        self.conv_block_2 = self. _cnn2d_block_2_conv_layer(32, 64)\n",
    "        self.conv_block_3 = self. _cnn2d_block_2_conv_layer(64, 128)\n",
    "        self.conv_block_4 = self. _cnn2d_block_2_conv_layer(128, 256)\n",
    "        \n",
    "        self.lstm_decoder = BidirectionalLSTM(nIn=9600,\n",
    "                                              nHidden=256,\n",
    "                                              nOut=number_classes)\n",
    "    \n",
    "    def _cnn2d_block_2_conv_layer(self, input_size, output_size):\n",
    "        conv2d_block = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(input_size,  output_size,  kernel_size=3, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Conv2d(output_size,  output_size,  kernel_size=3, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(2,2)\n",
    "        )\n",
    "        return conv2d_block\n",
    "    \n",
    "    def _cnn2d_block_1_conv_layer(self, input_size, output_size):\n",
    "        conv2d_block = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(input_size,  output_size,  kernel_size=3, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(2,2)\n",
    "        )\n",
    "        return conv2d_block\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x = x.permute(dims=(0, 2, 3, 4, 1))\n",
    "        x = self.conv_block_1(x)\n",
    "        x = self.conv_block_2(x)\n",
    "        x = self.conv_block_3(x)\n",
    "        x = self.conv_block_4(x)\n",
    "        shape = x.size()\n",
    "        # bs, 256, 3, 3, 14\n",
    "        x = x.view(shape[0], self.max_len, -1)  # bs, max_len, rest\n",
    "        x = self.lstm_decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba562711",
   "metadata": {},
   "source": [
    "# Define the dataloader in this task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c48aa66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "{'<blank>': 0, 'a': 1, 'b': 2, 'c': 3, 'd': 4, 'e': 5, 'f': 6, 'g': 7, 'h': 8, 'i': 9, 'j': 10, 'k': 11, 'l': 12, 'm': 13, 'n': 14, 'o': 15, 'p': 16, 'q': 17, 'r': 18, 's': 19, 't': 20, 'u': 21, 'v': 22, 'w': 23, 'x': 24, 'y': 25, 'z': 26, '<eos>': 27}\n",
      "train videos:171\n",
      "test videos:20\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "from cnn2d_image_generator import VideoDataset\n",
    "from image_2dcrnn import VideoModel\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import string\n",
    "import time\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "\n",
    "def make_char_dict():\n",
    "    chars = string.ascii_lowercase\n",
    "    char_dict = {\"<blank>\": 0}\n",
    "    for idx, c in enumerate(chars):\n",
    "        char_dict[c] = idx + 1\n",
    "    current_len = len(list(char_dict.keys()))\n",
    "    char_dict[\"<eos>\"] = current_len\n",
    "    print(char_dict)\n",
    "    return char_dict\n",
    "\n",
    "\n",
    "def get_train_test_folders():\n",
    "    test = open(\"data/eval_lst.txt\", \"r\", encoding=\"utf-8\").readlines()\n",
    "    train = open(\"data/train_lst.txt\", \"r\", encoding=\"utf-8\").readlines()\n",
    "    train_folders = [os.path.join(\"data\", \"data_aligned\", i.strip(\"\\n\")) for i in train]\n",
    "    test_folders = [os.path.join(\"data\", \"data_aligned\", i.strip(\"\\n\")) for i in test]\n",
    "    print(\"train videos:{}\".format(len(train_folders)))\n",
    "    print(\"test videos:{}\".format(len(test_folders)))\n",
    "    return train_folders, test_folders\n",
    "\n",
    "\n",
    "image_shape = (60, 60)\n",
    "\n",
    "char_dict = make_char_dict()\n",
    "train_folders, test_folders = get_train_test_folders()\n",
    "train_dataset = VideoDataset(\n",
    "    folder_list=train_folders,\n",
    "    char_dict=char_dict,\n",
    "    fixed_frame_num=200,\n",
    "    fixed_max_len=6,\n",
    "    image_shape=image_shape,\n",
    ")\n",
    "batch_size = 10\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset, batch_size=batch_size, shuffle=True\n",
    ")\n",
    "test_dataset = VideoDataset(\n",
    "    folder_list=test_folders,\n",
    "    char_dict=char_dict,\n",
    "    fixed_frame_num=200,\n",
    "    fixed_max_len=6,\n",
    "    aug=None,  # No need to do data augmentation in testing dataset\n",
    "    image_shape=image_shape,\n",
    ")\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset, batch_size=batch_size, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42bf5f13",
   "metadata": {},
   "source": [
    "# Init model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d30e7f6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VideoModel(\n",
      "  (conv_block_1): Sequential(\n",
      "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU()\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv_block_2): Sequential(\n",
      "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU()\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv_block_3): Sequential(\n",
      "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU()\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv_block_4): Sequential(\n",
      "    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU()\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (lstm_decoder): BidirectionalLSTM(\n",
      "    (rnn): LSTM(9600, 256, batch_first=True, bidirectional=True)\n",
      "    (embedding): Linear(in_features=512, out_features=28, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = VideoModel(number_classes=len(list(char_dict.keys())),\n",
    "                   max_len=6,\n",
    "                   image_shape=image_shape)\n",
    "model = model.to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b085bfb",
   "metadata": {},
   "source": [
    "# Set up for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7444645a",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1, momentum=0.9)\n",
    "\n",
    "steps_per_epoch = len(train_folders) // 10 + 1\n",
    "epochs = 10\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,\n",
    "                                                       mode='min',\n",
    "                                                       verbose=True,\n",
    "                                                       factor=0.1,\n",
    "                                                       patience=5,\n",
    "                                                       threshold=0.00001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2f90c8",
   "metadata": {},
   "source": [
    "# Define training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c4a14169",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_process():\n",
    "    running_loss = 0\n",
    "    num_batches = 0\n",
    "\n",
    "    model.train()\n",
    "    for idx, data in enumerate(train_dataloader):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        x, y = data\n",
    "        size = y.size()\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        x.requires_grad_()\n",
    "\n",
    "        scores = model(x)\n",
    "\n",
    "        scores = scores.view(size[0] * size[1], -1)\n",
    "        y = y.view(size[0] * size[1])\n",
    "        loss = criterion(scores, y)\n",
    "\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 5)\n",
    "        optimizer.step()\n",
    "        running_loss += loss.detach().item()\n",
    "        num_batches += 1\n",
    "        print(\"time:{}, epoch: {} step: {}, avg running loss is {}\".format(\n",
    "            time.ctime(), epoch + 1, idx + 1, running_loss / num_batches\n",
    "        ))\n",
    "    return running_loss, num_batches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c312a56c",
   "metadata": {},
   "source": [
    "# Define validation process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8eb96606",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing_process():\n",
    "    running_loss = 0\n",
    "    num_batches = 0\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for idx, data in enumerate(test_dataloader):\n",
    "            x, y = data\n",
    "            size = y.size()\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            scores = model(x)\n",
    "\n",
    "            scores = scores.view(size[0] * size[1], -1)\n",
    "            y = y.view(size[0] * size[1])\n",
    "            loss = criterion(scores, y)\n",
    "            running_loss += loss.item()\n",
    "            num_batches += 1\n",
    "    return running_loss, num_batches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb04ecec",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ec95cb06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time:Thu Nov 18 16:31:22 2021, epoch: 1 step: 1, avg running loss is 3.3331379890441895\n",
      "time:Thu Nov 18 16:31:29 2021, epoch: 1 step: 2, avg running loss is 3.23698627948761\n",
      "time:Thu Nov 18 16:31:35 2021, epoch: 1 step: 3, avg running loss is 3.0955111980438232\n",
      "time:Thu Nov 18 16:31:40 2021, epoch: 1 step: 4, avg running loss is 2.996290445327759\n",
      "time:Thu Nov 18 16:31:45 2021, epoch: 1 step: 5, avg running loss is 2.969486379623413\n",
      "time:Thu Nov 18 16:31:50 2021, epoch: 1 step: 6, avg running loss is 2.854193329811096\n",
      "time:Thu Nov 18 16:31:56 2021, epoch: 1 step: 7, avg running loss is 2.8410747732434953\n",
      "time:Thu Nov 18 16:32:02 2021, epoch: 1 step: 8, avg running loss is 2.8046317100524902\n",
      "time:Thu Nov 18 16:32:08 2021, epoch: 1 step: 9, avg running loss is 2.768410470750597\n",
      "time:Thu Nov 18 16:32:13 2021, epoch: 1 step: 10, avg running loss is 2.741999077796936\n",
      "time:Thu Nov 18 16:32:18 2021, epoch: 1 step: 11, avg running loss is 2.7109274213964287\n",
      "time:Thu Nov 18 16:32:23 2021, epoch: 1 step: 12, avg running loss is 2.6792824467023215\n",
      "time:Thu Nov 18 16:32:29 2021, epoch: 1 step: 13, avg running loss is 2.6159589840815616\n",
      "time:Thu Nov 18 16:32:34 2021, epoch: 1 step: 14, avg running loss is 2.6393140043531145\n",
      "time:Thu Nov 18 16:32:39 2021, epoch: 1 step: 15, avg running loss is 2.641049385070801\n",
      "time:Thu Nov 18 16:32:45 2021, epoch: 1 step: 16, avg running loss is 2.6350724548101425\n",
      "time:Thu Nov 18 16:32:51 2021, epoch: 1 step: 17, avg running loss is 2.6080312308143165\n",
      "time:Thu Nov 18 16:32:52 2021, epoch: 1 step: 18, avg running loss is 2.576185557577345\n",
      "****************************************************************************************************\n",
      "epoch: 1, avg training loss:2.576185557577345, avg validation loss:2.804356336593628\n",
      "****************************************************************************************************\n",
      "time:Thu Nov 18 16:33:00 2021, epoch: 2 step: 1, avg running loss is 2.938441514968872\n",
      "time:Thu Nov 18 16:33:06 2021, epoch: 2 step: 2, avg running loss is 2.682435631752014\n",
      "time:Thu Nov 18 16:33:11 2021, epoch: 2 step: 3, avg running loss is 2.5275964736938477\n",
      "time:Thu Nov 18 16:33:17 2021, epoch: 2 step: 4, avg running loss is 2.5191310048103333\n",
      "time:Thu Nov 18 16:33:22 2021, epoch: 2 step: 5, avg running loss is 2.757341909408569\n",
      "time:Thu Nov 18 16:33:28 2021, epoch: 2 step: 6, avg running loss is 2.8350812991460166\n",
      "time:Thu Nov 18 16:33:35 2021, epoch: 2 step: 7, avg running loss is 2.8775265216827393\n",
      "time:Thu Nov 18 16:33:40 2021, epoch: 2 step: 8, avg running loss is 2.892793118953705\n",
      "time:Thu Nov 18 16:33:45 2021, epoch: 2 step: 9, avg running loss is 2.865904516643948\n",
      "time:Thu Nov 18 16:33:52 2021, epoch: 2 step: 10, avg running loss is 2.79953351020813\n",
      "time:Thu Nov 18 16:33:57 2021, epoch: 2 step: 11, avg running loss is 2.7931494496085425\n",
      "time:Thu Nov 18 16:34:02 2021, epoch: 2 step: 12, avg running loss is 2.764684021472931\n",
      "time:Thu Nov 18 16:34:09 2021, epoch: 2 step: 13, avg running loss is 2.7566516949580264\n",
      "time:Thu Nov 18 16:34:15 2021, epoch: 2 step: 14, avg running loss is 2.722273656300136\n",
      "time:Thu Nov 18 16:34:23 2021, epoch: 2 step: 15, avg running loss is 2.7001084963480633\n",
      "time:Thu Nov 18 16:34:28 2021, epoch: 2 step: 16, avg running loss is 2.6820237785577774\n",
      "time:Thu Nov 18 16:34:33 2021, epoch: 2 step: 17, avg running loss is 2.6773840259103214\n",
      "time:Thu Nov 18 16:34:34 2021, epoch: 2 step: 18, avg running loss is 2.6359143323368497\n",
      "****************************************************************************************************\n",
      "epoch: 2, avg training loss:2.6359143323368497, avg validation loss:3.8058773279190063\n",
      "****************************************************************************************************\n",
      "time:Thu Nov 18 16:34:46 2021, epoch: 3 step: 1, avg running loss is 3.3630497455596924\n",
      "time:Thu Nov 18 16:34:52 2021, epoch: 3 step: 2, avg running loss is 3.542993426322937\n",
      "time:Thu Nov 18 16:34:58 2021, epoch: 3 step: 3, avg running loss is 3.290593147277832\n",
      "time:Thu Nov 18 16:35:04 2021, epoch: 3 step: 4, avg running loss is 3.1548481583595276\n",
      "time:Thu Nov 18 16:35:10 2021, epoch: 3 step: 5, avg running loss is 3.161145830154419\n",
      "time:Thu Nov 18 16:35:16 2021, epoch: 3 step: 6, avg running loss is 3.2470460335413613\n",
      "time:Thu Nov 18 16:35:23 2021, epoch: 3 step: 7, avg running loss is 3.207347427095686\n",
      "time:Thu Nov 18 16:35:31 2021, epoch: 3 step: 8, avg running loss is 3.23416006565094\n",
      "time:Thu Nov 18 16:35:37 2021, epoch: 3 step: 9, avg running loss is 3.242819653617011\n",
      "time:Thu Nov 18 16:35:42 2021, epoch: 3 step: 10, avg running loss is 3.2041067600250246\n",
      "time:Thu Nov 18 16:35:47 2021, epoch: 3 step: 11, avg running loss is 3.1516795591874556\n",
      "time:Thu Nov 18 16:35:53 2021, epoch: 3 step: 12, avg running loss is 3.1723199486732483\n",
      "time:Thu Nov 18 16:36:09 2021, epoch: 3 step: 13, avg running loss is 3.23875748194181\n",
      "time:Thu Nov 18 16:36:16 2021, epoch: 3 step: 14, avg running loss is 3.256271617753165\n",
      "time:Thu Nov 18 16:36:21 2021, epoch: 3 step: 15, avg running loss is 3.208100668589274\n",
      "time:Thu Nov 18 16:36:34 2021, epoch: 3 step: 16, avg running loss is 3.151660442352295\n",
      "time:Thu Nov 18 16:36:41 2021, epoch: 3 step: 17, avg running loss is 3.192951623131247\n",
      "time:Thu Nov 18 16:36:42 2021, epoch: 3 step: 18, avg running loss is 3.190782454278734\n",
      "****************************************************************************************************\n",
      "epoch: 3, avg training loss:3.190782454278734, avg validation loss:3.915014147758484\n",
      "****************************************************************************************************\n",
      "time:Thu Nov 18 16:36:57 2021, epoch: 4 step: 1, avg running loss is 4.562222480773926\n",
      "time:Thu Nov 18 16:37:06 2021, epoch: 4 step: 2, avg running loss is 4.7805469036102295\n",
      "time:Thu Nov 18 16:37:20 2021, epoch: 4 step: 3, avg running loss is 4.535540580749512\n",
      "time:Thu Nov 18 16:37:30 2021, epoch: 4 step: 4, avg running loss is 4.303649127483368\n",
      "time:Thu Nov 18 16:37:46 2021, epoch: 4 step: 5, avg running loss is 4.1354598045349125\n",
      "time:Thu Nov 18 16:38:06 2021, epoch: 4 step: 6, avg running loss is 3.9425770044326782\n",
      "time:Thu Nov 18 16:38:12 2021, epoch: 4 step: 7, avg running loss is 3.923554011753627\n",
      "time:Thu Nov 18 16:38:18 2021, epoch: 4 step: 8, avg running loss is 4.017926454544067\n",
      "time:Thu Nov 18 16:38:25 2021, epoch: 4 step: 9, avg running loss is 4.109528011745876\n",
      "time:Thu Nov 18 16:38:34 2021, epoch: 4 step: 10, avg running loss is 3.990706467628479\n",
      "time:Thu Nov 18 16:38:41 2021, epoch: 4 step: 11, avg running loss is 3.9777932167053223\n",
      "time:Thu Nov 18 16:38:51 2021, epoch: 4 step: 12, avg running loss is 3.9853532314300537\n",
      "time:Thu Nov 18 16:38:56 2021, epoch: 4 step: 13, avg running loss is 3.977531616504376\n",
      "time:Thu Nov 18 16:39:01 2021, epoch: 4 step: 14, avg running loss is 3.917381610189165\n",
      "time:Thu Nov 18 16:39:06 2021, epoch: 4 step: 15, avg running loss is 3.911513264973958\n",
      "time:Thu Nov 18 16:39:12 2021, epoch: 4 step: 16, avg running loss is 3.9059549272060394\n",
      "time:Thu Nov 18 16:39:17 2021, epoch: 4 step: 17, avg running loss is 3.8605385668137493\n",
      "time:Thu Nov 18 16:39:17 2021, epoch: 4 step: 18, avg running loss is 3.8585297928916082\n",
      "****************************************************************************************************\n",
      "epoch: 4, avg training loss:3.8585297928916082, avg validation loss:3.5722755193710327\n",
      "****************************************************************************************************\n",
      "time:Thu Nov 18 16:39:25 2021, epoch: 5 step: 1, avg running loss is 3.5110890865325928\n",
      "time:Thu Nov 18 16:39:31 2021, epoch: 5 step: 2, avg running loss is 3.680137276649475\n",
      "time:Thu Nov 18 16:39:36 2021, epoch: 5 step: 3, avg running loss is 3.6079739729563394\n",
      "time:Thu Nov 18 16:39:41 2021, epoch: 5 step: 4, avg running loss is 3.4182721376419067\n",
      "time:Thu Nov 18 16:39:47 2021, epoch: 5 step: 5, avg running loss is 3.746165657043457\n",
      "time:Thu Nov 18 16:39:53 2021, epoch: 5 step: 6, avg running loss is 3.742116848627726\n",
      "time:Thu Nov 18 16:39:59 2021, epoch: 5 step: 7, avg running loss is 3.7037054130009244\n",
      "time:Thu Nov 18 16:40:04 2021, epoch: 5 step: 8, avg running loss is 3.680000424385071\n",
      "time:Thu Nov 18 16:40:10 2021, epoch: 5 step: 9, avg running loss is 3.6692428323957653\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time:Thu Nov 18 16:40:15 2021, epoch: 5 step: 10, avg running loss is 3.665429949760437\n",
      "time:Thu Nov 18 16:40:21 2021, epoch: 5 step: 11, avg running loss is 3.6101166768507524\n",
      "time:Thu Nov 18 16:40:25 2021, epoch: 5 step: 12, avg running loss is 3.5473761359850564\n",
      "time:Thu Nov 18 16:40:30 2021, epoch: 5 step: 13, avg running loss is 3.5040150605715237\n",
      "time:Thu Nov 18 16:40:35 2021, epoch: 5 step: 14, avg running loss is 3.5232543775013516\n",
      "time:Thu Nov 18 16:40:40 2021, epoch: 5 step: 15, avg running loss is 3.4981461842854817\n",
      "time:Thu Nov 18 16:40:45 2021, epoch: 5 step: 16, avg running loss is 3.4872216433286667\n",
      "time:Thu Nov 18 16:40:49 2021, epoch: 5 step: 17, avg running loss is 3.4649929299074063\n",
      "time:Thu Nov 18 16:40:50 2021, epoch: 5 step: 18, avg running loss is 3.553756594657898\n",
      "****************************************************************************************************\n",
      "epoch: 5, avg training loss:3.553756594657898, avg validation loss:3.7243123054504395\n",
      "****************************************************************************************************\n",
      "time:Thu Nov 18 16:40:58 2021, epoch: 6 step: 1, avg running loss is 3.4757919311523438\n",
      "time:Thu Nov 18 16:41:03 2021, epoch: 6 step: 2, avg running loss is 3.7162365913391113\n",
      "time:Thu Nov 18 16:41:08 2021, epoch: 6 step: 3, avg running loss is 3.6400256951649985\n",
      "time:Thu Nov 18 16:41:13 2021, epoch: 6 step: 4, avg running loss is 3.7946168780326843\n",
      "time:Thu Nov 18 16:41:18 2021, epoch: 6 step: 5, avg running loss is 3.7021368503570558\n",
      "time:Thu Nov 18 16:41:23 2021, epoch: 6 step: 6, avg running loss is 3.619005719820658\n",
      "time:Thu Nov 18 16:41:28 2021, epoch: 6 step: 7, avg running loss is 3.562701463699341\n",
      "time:Thu Nov 18 16:41:33 2021, epoch: 6 step: 8, avg running loss is 3.6555008590221405\n",
      "time:Thu Nov 18 16:41:38 2021, epoch: 6 step: 9, avg running loss is 3.672795295715332\n",
      "time:Thu Nov 18 16:41:42 2021, epoch: 6 step: 10, avg running loss is 3.656265211105347\n",
      "time:Thu Nov 18 16:41:47 2021, epoch: 6 step: 11, avg running loss is 3.691583113236861\n",
      "time:Thu Nov 18 16:41:53 2021, epoch: 6 step: 12, avg running loss is 3.7102989554405212\n",
      "time:Thu Nov 18 16:42:01 2021, epoch: 6 step: 13, avg running loss is 3.7264346342820387\n",
      "time:Thu Nov 18 16:42:07 2021, epoch: 6 step: 14, avg running loss is 3.6895193542752946\n",
      "time:Thu Nov 18 16:42:12 2021, epoch: 6 step: 15, avg running loss is 3.6754825115203857\n",
      "time:Thu Nov 18 16:42:17 2021, epoch: 6 step: 16, avg running loss is 3.6037694066762924\n",
      "time:Thu Nov 18 16:42:22 2021, epoch: 6 step: 17, avg running loss is 3.550991114448099\n",
      "time:Thu Nov 18 16:42:22 2021, epoch: 6 step: 18, avg running loss is 3.4506239824824863\n",
      "****************************************************************************************************\n",
      "epoch: 6, avg training loss:3.4506239824824863, avg validation loss:3.8601990938186646\n",
      "****************************************************************************************************\n",
      "time:Thu Nov 18 16:42:30 2021, epoch: 7 step: 1, avg running loss is 2.8737614154815674\n",
      "time:Thu Nov 18 16:42:35 2021, epoch: 7 step: 2, avg running loss is 3.5299683809280396\n",
      "time:Thu Nov 18 16:42:39 2021, epoch: 7 step: 3, avg running loss is 3.390338579813639\n",
      "time:Thu Nov 18 16:42:44 2021, epoch: 7 step: 4, avg running loss is 3.3547439575195312\n",
      "time:Thu Nov 18 16:42:49 2021, epoch: 7 step: 5, avg running loss is 3.187239646911621\n",
      "time:Thu Nov 18 16:42:54 2021, epoch: 7 step: 6, avg running loss is 3.271111011505127\n",
      "time:Thu Nov 18 16:42:59 2021, epoch: 7 step: 7, avg running loss is 3.2237147944314137\n",
      "time:Thu Nov 18 16:43:04 2021, epoch: 7 step: 8, avg running loss is 3.2411869764328003\n",
      "time:Thu Nov 18 16:43:09 2021, epoch: 7 step: 9, avg running loss is 3.2632129192352295\n",
      "time:Thu Nov 18 16:43:16 2021, epoch: 7 step: 10, avg running loss is 3.2750692844390867\n",
      "time:Thu Nov 18 16:43:21 2021, epoch: 7 step: 11, avg running loss is 3.259511427445845\n",
      "time:Thu Nov 18 16:43:27 2021, epoch: 7 step: 12, avg running loss is 3.228615383307139\n",
      "time:Thu Nov 18 16:43:33 2021, epoch: 7 step: 13, avg running loss is 3.2076833064739523\n",
      "time:Thu Nov 18 16:43:38 2021, epoch: 7 step: 14, avg running loss is 3.206853883607047\n",
      "time:Thu Nov 18 16:43:42 2021, epoch: 7 step: 15, avg running loss is 3.186889886856079\n",
      "time:Thu Nov 18 16:43:48 2021, epoch: 7 step: 16, avg running loss is 3.231533780694008\n",
      "time:Thu Nov 18 16:43:54 2021, epoch: 7 step: 17, avg running loss is 3.218178903355318\n",
      "time:Thu Nov 18 16:43:55 2021, epoch: 7 step: 18, avg running loss is 3.256341298421224\n",
      "****************************************************************************************************\n",
      "epoch: 7, avg training loss:3.256341298421224, avg validation loss:3.3185373544692993\n",
      "Epoch     7: reducing learning rate of group 0 to 1.0000e-01.\n",
      "****************************************************************************************************\n",
      "time:Thu Nov 18 16:44:03 2021, epoch: 8 step: 1, avg running loss is 3.351832151412964\n",
      "time:Thu Nov 18 16:44:08 2021, epoch: 8 step: 2, avg running loss is 3.256162643432617\n",
      "time:Thu Nov 18 16:44:13 2021, epoch: 8 step: 3, avg running loss is 3.1973625818888345\n",
      "time:Thu Nov 18 16:44:21 2021, epoch: 8 step: 4, avg running loss is 3.1610149145126343\n",
      "time:Thu Nov 18 16:44:26 2021, epoch: 8 step: 5, avg running loss is 3.141410255432129\n",
      "time:Thu Nov 18 16:44:32 2021, epoch: 8 step: 6, avg running loss is 3.0759392976760864\n",
      "time:Thu Nov 18 16:44:38 2021, epoch: 8 step: 7, avg running loss is 3.001249143055507\n",
      "time:Thu Nov 18 16:44:44 2021, epoch: 8 step: 8, avg running loss is 2.9547686874866486\n",
      "time:Thu Nov 18 16:44:50 2021, epoch: 8 step: 9, avg running loss is 2.9125541581047907\n",
      "time:Thu Nov 18 16:44:55 2021, epoch: 8 step: 10, avg running loss is 2.9524591684341432\n",
      "time:Thu Nov 18 16:45:01 2021, epoch: 8 step: 11, avg running loss is 2.8822286345741968\n",
      "time:Thu Nov 18 16:45:06 2021, epoch: 8 step: 12, avg running loss is 2.8597959081331887\n",
      "time:Thu Nov 18 16:45:14 2021, epoch: 8 step: 13, avg running loss is 2.8034765353569617\n",
      "time:Thu Nov 18 16:45:21 2021, epoch: 8 step: 14, avg running loss is 2.7468072175979614\n",
      "time:Thu Nov 18 16:45:26 2021, epoch: 8 step: 15, avg running loss is 2.7832578500111897\n",
      "time:Thu Nov 18 16:45:31 2021, epoch: 8 step: 16, avg running loss is 2.7953308522701263\n",
      "time:Thu Nov 18 16:45:36 2021, epoch: 8 step: 17, avg running loss is 2.7534639835357666\n",
      "time:Thu Nov 18 16:45:36 2021, epoch: 8 step: 18, avg running loss is 2.748241345087687\n",
      "****************************************************************************************************\n",
      "epoch: 8, avg training loss:2.748241345087687, avg validation loss:2.6714463233947754\n",
      "****************************************************************************************************\n",
      "time:Thu Nov 18 16:45:47 2021, epoch: 9 step: 1, avg running loss is 2.895221471786499\n",
      "time:Thu Nov 18 16:45:51 2021, epoch: 9 step: 2, avg running loss is 2.5905117988586426\n",
      "time:Thu Nov 18 16:45:57 2021, epoch: 9 step: 3, avg running loss is 2.48973282178243\n",
      "time:Thu Nov 18 16:46:02 2021, epoch: 9 step: 4, avg running loss is 2.412895381450653\n",
      "time:Thu Nov 18 16:46:07 2021, epoch: 9 step: 5, avg running loss is 2.4520607948303224\n",
      "time:Thu Nov 18 16:46:12 2021, epoch: 9 step: 6, avg running loss is 2.432852625846863\n",
      "time:Thu Nov 18 16:46:17 2021, epoch: 9 step: 7, avg running loss is 2.414367130824498\n",
      "time:Thu Nov 18 16:46:22 2021, epoch: 9 step: 8, avg running loss is 2.449501872062683\n",
      "time:Thu Nov 18 16:46:28 2021, epoch: 9 step: 9, avg running loss is 2.435863627327813\n",
      "time:Thu Nov 18 16:46:34 2021, epoch: 9 step: 10, avg running loss is 2.437112832069397\n",
      "time:Thu Nov 18 16:46:40 2021, epoch: 9 step: 11, avg running loss is 2.4302820725874468\n",
      "time:Thu Nov 18 16:46:45 2021, epoch: 9 step: 12, avg running loss is 2.4263987143834433\n",
      "time:Thu Nov 18 16:46:50 2021, epoch: 9 step: 13, avg running loss is 2.4623807210188646\n",
      "time:Thu Nov 18 16:46:56 2021, epoch: 9 step: 14, avg running loss is 2.4766645772116527\n",
      "time:Thu Nov 18 16:47:02 2021, epoch: 9 step: 15, avg running loss is 2.4583001454671223\n",
      "time:Thu Nov 18 16:47:07 2021, epoch: 9 step: 16, avg running loss is 2.432771772146225\n",
      "time:Thu Nov 18 16:47:13 2021, epoch: 9 step: 17, avg running loss is 2.413793914458331\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time:Thu Nov 18 16:47:13 2021, epoch: 9 step: 18, avg running loss is 2.3701753748787775\n",
      "****************************************************************************************************\n",
      "epoch: 9, avg training loss:2.3701753748787775, avg validation loss:2.55965518951416\n",
      "****************************************************************************************************\n",
      "time:Thu Nov 18 16:47:22 2021, epoch: 10 step: 1, avg running loss is 1.9023246765136719\n",
      "time:Thu Nov 18 16:47:28 2021, epoch: 10 step: 2, avg running loss is 2.592995524406433\n",
      "time:Thu Nov 18 16:47:34 2021, epoch: 10 step: 3, avg running loss is 2.4896981716156006\n",
      "time:Thu Nov 18 16:47:39 2021, epoch: 10 step: 4, avg running loss is 2.4361849427223206\n",
      "time:Thu Nov 18 16:47:44 2021, epoch: 10 step: 5, avg running loss is 2.375188636779785\n",
      "time:Thu Nov 18 16:47:51 2021, epoch: 10 step: 6, avg running loss is 2.3305323918660483\n",
      "time:Thu Nov 18 16:47:56 2021, epoch: 10 step: 7, avg running loss is 2.3427252769470215\n",
      "time:Thu Nov 18 16:48:01 2021, epoch: 10 step: 8, avg running loss is 2.3189965188503265\n",
      "time:Thu Nov 18 16:48:08 2021, epoch: 10 step: 9, avg running loss is 2.3157027297549777\n",
      "time:Thu Nov 18 16:48:13 2021, epoch: 10 step: 10, avg running loss is 2.2853735208511354\n",
      "time:Thu Nov 18 16:48:18 2021, epoch: 10 step: 11, avg running loss is 2.311504450711337\n",
      "time:Thu Nov 18 16:48:24 2021, epoch: 10 step: 12, avg running loss is 2.3021687467892966\n",
      "time:Thu Nov 18 16:48:30 2021, epoch: 10 step: 13, avg running loss is 2.3024023862985463\n",
      "time:Thu Nov 18 16:48:35 2021, epoch: 10 step: 14, avg running loss is 2.308688163757324\n",
      "time:Thu Nov 18 16:48:39 2021, epoch: 10 step: 15, avg running loss is 2.327957518895467\n",
      "time:Thu Nov 18 16:48:45 2021, epoch: 10 step: 16, avg running loss is 2.3339405953884125\n",
      "time:Thu Nov 18 16:48:50 2021, epoch: 10 step: 17, avg running loss is 2.3400728983037613\n",
      "time:Thu Nov 18 16:48:50 2021, epoch: 10 step: 18, avg running loss is 2.3609229458702936\n",
      "****************************************************************************************************\n",
      "epoch: 10, avg training loss:2.3609229458702936, avg validation loss:2.4704357385635376\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    running_loss, num_batches = train_process()\n",
    "    test_running_loss, test_num_batches = testing_process()\n",
    "    print(\"*\" * 100)\n",
    "    print(\"epoch: {}, avg training loss:{}, avg validation loss:{}\".format(epoch + 1, running_loss / num_batches,\n",
    "                                                                           test_running_loss / test_num_batches))\n",
    "    scheduler.step(test_running_loss / test_num_batches)\n",
    "    print(\"*\" * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6095b513",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_col, k_row = 5, 5\n",
    "save_name = '2dcrnn_model_'+str(k_col*k_row)+'_epoch_'+str(epochs)+'.pkl'\n",
    "torch.save(model, save_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3299fd",
   "metadata": {},
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ce29e110",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(save_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb749c6",
   "metadata": {},
   "source": [
    "# Test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bf84f230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc in inference process is 0.32499998807907104\n"
     ]
    }
   ],
   "source": [
    "def compute_val_acc(scores, y):\n",
    "    num = scores.size(0)\n",
    "    prediction = scores.argmax(dim=1)\n",
    "    indicator = (prediction == y)\n",
    "    num_matches = indicator.sum()\n",
    "    return num_matches.float() / num\n",
    "\n",
    "\n",
    "model.eval()\n",
    "acc = 0\n",
    "count = 0\n",
    "with torch.no_grad():\n",
    "    for idx, data in enumerate(test_dataloader):\n",
    "        x, y = data\n",
    "        size = y.size()\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        scores = model(x)\n",
    "\n",
    "        scores = scores.view(size[0] * size[1], -1)\n",
    "        y = y.view(size[0] * size[1])\n",
    "        acc += compute_val_acc(scores, y)\n",
    "        count += 1\n",
    "\n",
    "print(\"Acc in inference process is {}\".format(acc / count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f3ffb0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
